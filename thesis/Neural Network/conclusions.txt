We proposed an amendment to the architecture of GRU RNN by using SVM as its final output layer in a binary/non-probabilistic classification task. This amendment was seen as viable for the fast prediction time of SVM compared to Softmax. To test the model, we conducted an experiment comparing it with the established GRU-Softmax model. Consequently, the empirical data attests to the effectiveness of the proposed GRU-SVM model over its comparator in terms of predictive accuracy, and training and testing time.
Further work must be done to validate the effectiveness of the proposed GRU-SVM model in other binary classification tasks. Extended study on the proposed model for a faster multinomial clas sification would prove to be prolific as well. Lastly, the theory presented to explain the relatively low performance of the Soft max function as a binary classifier might be a pre-cursor to further studies.
The effectiveness of the proposed method is evaluated by comparing the results of LF DCT coefficients with in terms of robustness against a series of attacks such as JPEG compression, low pass filtering, median filtering, scaling, contrast enhancement and addition of noise. The NC value obtained against these attacks along with the visual quality of extracted watermark is listed in Table 3.4. Column 1 of Table 3.4 lists the attacks in following order: 1. Attack Free, 2. Median Filtering, 3. Low-pass Filtering (LPF), 4. JPEG (QF=90), 5. JPEG (QF=60), 6. Scaling (75%), 7. Scaling (50%), 8. Salt & Pepper Noise (0.02) and 9. LACE. From Table 3.4, high NC value against image processing operations as compared with [Meng et al., 2008] on Lena image shows the good learning potential and high generalization against noisy datasets of LTSVR. The selection of blocks according to the fuzzy entropy and inserting the watermark into LF DCT coefficients provides the imperceptibility and good visual quality of watermarked image. The effect of low, middle and high frequency DCT coefficients onto gray scale image watermarking using LTSVR in terms of robustness after applying image processing operation is examined. From the results obtained from experiment, it is observed that LF DCT coefficients are more appropriate than MF and HF DCT coefficients to insert the watermark. In addition to the selection of LF DCT coefficient, the utilization of LTSVR onto image watermarking proves its good learning potential and high generalization nature against noisy dataset. Experimental results on different textured images which involve real world and standard images prove that the presented image watermarking method can be utilized in real world application. The proposed method uses single scaling factor to insert the watermark in all the chosen blocks that are obtained after applying a large number of experiments on all images. In future, based on the ability of noise sensing of each block, watermark strength is decided using evolutionary approaches to enhance the robustness.
 The generalization performance of the newly developed machine learning algorithm LTSVR against noisy datasets has been tested on synthetic datasets [Murphy and Aha, 1992], is successfully applied onto image watermarking application to enhance the robustness against image processing attacks in the field of image watermarking. A new imperceptible, robust and secure grayscale image watermarking scheme through the combination of GA and LTSVR in DCT domain is proposed. Selected number of blocks based on fuzzy entropy not only reduces the dimensionality of the watermarking problem but also discards redundant and irrelevant blocks. In order to find the optimal scaling factors to control the strength of watermark, GA is used. Because of the good learning capability of image characteristics and high generalization ability of LTSVR against noisy datasets, significant amount of robustness is achieved. Among all of the compared schemes, our scheme proves its superiority in terms of robustness against image processing attacks as demonstrated through the experimental results. Our proposed method will help to improve the imperceptibility and robustness against common signal processing attacks and some of the geometric attacks but the scheme proposed in this manuscript lacks to show resistance against rotation and deforming attacks. In future, our main concerns is to extract image features which show resistance against rotation and translation attacks for more robust image watermarking applications.
In this work, an effective approach of gray scale image watermarking using LTSVR and through the combination of wavelet transform and QR decomposition is described for copy right protection applications. Fuzzy entropy is not only used to discard the regions of the image which are not relevant to embed the watermark but also reduces the time complexity. Selection of LL sub band using LWT and appropriate coefficient selection of each region using QR decomposition results in enhancing the performance as measured by imperceptibility and robustness. The robustness measured by different kinds of attacks performed on test images is accomplished by the good generalization property of LTSVR as revealed from the experimental results using proposed approach. The scrambled watermark obtained using Arnold transformation provides the security to the original watermark. The experimental and comparison results on different textured images with the existing methods proves that the approach described in this paper attains imperceptibility as well as robustness.
Digital watermarking is one of the most widely used approaches which is considered as a powerful tool for providing the copyright protection, copy protection and ownership assertion of digital multimedia contents. In digital watermarking, the copyright information is embedded directly into the digital content in such a way that it always survive even after processing attacks. The contribution of this thesis is in the area of digital image watermarking by using intelligent machine learning algorithms to set trade offs between various watermarking parameters. Machine learning techniques are applied in different watermarking schmes in order to achieve optimization and to get superior results as compared to contemporary techniques. We have successfully set trade offs between watermark robustness and imperceptibility, while keeping the payload constant.
 we developed a watermarking schemes in discrete cosine transform domain. LF, MF and HF DCT block are used for watermark embedding. Fuzzy entropy is used for selecting smooth non overlapping blocks. Dataset is formed from the first nine LF DCT coefficients of each DCT block selected in zigzag manner. Odd number of samples are used to train the LTSVR and even number of samples are used to embed the watermark. From the experimental results on various textured images, it is found that LF DCT coefficient, which contains the maximum energy of signal, provides siginificant amount of robustness as compared to MF and HF DCT coefficient against different image processing attacks. 
we have proposed two schemes of image watermarking using Lagrangian twin support vector regression (LTSVR) and combination of a variant of wavelet transform and QR decomposition. One scheme is a combination of LTSVR and QR decomposition in LWT domain and second is LTSVR and QR decomposition in IWT domain. Fuzzy entropy is used to select the smooth non  overlapping block and Arnold transformation is used for security of watermark. Experimental result shows that both schemes are highly imperceptible and robust against various kinds of image operations.
This technique is a hybrid of LTSVR and GA in DCT domain. Fuzzy entropy is used to select the relevant blocks for embedding the watermark. Significant DCT coefficients having high energy compaction property of each selected block are used to form the image dataset to train LTSVR to find the non-linear regression function between the input and target vector. The adaptive watermark strength, different for each selected block, is decided by the GA process based on well defined fitness function. From the experimental and comparison results, it is inferred that the proposed method is suitable for copyright protection applications where high degree of robustness is desirable.
The main subject of this thesis has been to implement RNNs in time series. Initially we work with linear univariate time series as a proof of concept for our RNN implementation.
We examine if the order of the time series should be taken into account in the structure of the network for time series forecasting. Then we explore if the size of the hidden layer affects the training and then we apply different regularization techniques. Based on the empirical results of the experiments with linear data we continue with non-linear univariate and multivariate time series. In the setting of multivariate time series we train the network with the classic way of training using RNNs and we also present a new method for Granger causal discovery in multivariate time series called rnnGL.
From the experiments with linear univariate time series we show that by using RNNs for time series prediction no previous knowledge about the time lag dependencies of the time series is needed. The network is able to learn alone its own history due to the recurrency of the hidden layer. As a result, it is enough to give only one input unit each time. The size of the hidden layer should be carefully chosen because it can cause overfitting. To avoid problems like this it is better to train the network with a large number of hidden units using a regularization technique. The regularization techniques improve the performance of the network, especially for the smaller data sets. Moreover, RNNs results are similar to the ones obtained with linear regression. However, using RNNs for linear data is an overkill since these can be learned by simple linear models with less effort and using much smaller data samples. From the experiment with non-linear univariate time series we show that RNNs perform very well for non-linear data. By using RNNs the model fits not only the past data (training data sets), but the new ones as well (test data set) despite the non-linearity of the data. The performance of RNNs is superior to the linear regression method in this case, having the additional advantage that no previous knowledge of the process order is required. Moreover, the use of a regularization technique helps the prediction and as the size of the training data set increases the MSE improves.
From the last experiment we show that RNNs work also well in the setting of non-linear multivariate time series one-step ahead prediction. Our method, rrnGL is able to discover correctly the Granger relations between the time series especially for training samples with size 1000 or greater. Moreover our model improves the prediction for small sample sizes, in contrast to larger data sets where the classic way of training using RNNs seems to perform better. A possible explanation is that when the size of the training sample is large the network is capable to learn the possible Granger relations between the inputs and takes them into account for the prediction. For large training data sets however, in contrast to our expectations, the rnnGL method performs worse compared to the classic RNNs but further studies are required for this to be understood.
We have demonstrated that discriminative DNN models are easily fooled in that they classify many unrecognizable images with near-certainty as members of a recognizable class. Two different ways of encoding evolutionary algorithms produce two qualitatively different types of unrecognizable ¡°fooling images¡±, and gradient ascent produces a third. That DNNs see these objects as near-perfect examples of recognizable images sheds light on remaining differences between the way DNNs and humans recognize objects, raising questions about the true generalization capabilities of DNNs and the potential for costly exploits of solutions that use DNNs.
This paper introduces the concept of the Innovation Engine. It then describes a version of Innovation Engines that can be created with existing deep learning technology, relying on DNNs trained with supervised learning. It also describes a more ambitious Innovation Engine that will take advantage of unsupervised learning technology once it is more mature. Our paper also also offers a first empirical investigation into many different aspects of Innovation Engines, including why they work and the degree to which they promote evolvability.
All of the work in this paper is in the domain of generating images. However, Innovation Engines should theoretically work in any domain, but future work is required to validate that hypothesis. In a future study, we will create Innovation Engines in more quantitative domains. For example, we will pair DNNs trained to recognize different actions in videos with evolutionary algorithms to attempt to automatically create neural network robot controllers for thousands of different robotic behaviors. DNNs already can classify the actions taking place in videos, and EAs can evolve neural networks to produce a variety of robot behaviors, so we are optimistic that an Innovation Engine in this domain will be successful. That said, its computational costs will be substantial, given how expensive it is to both have DNNs evaluate videos and for EAs to simulate robot behaviors. Our results have shown that the Innovation Engine concept is worth exploring further. Specifically, we have supported some of its key assumptions: that evolving toward many objectives simultaneously approximates divergent search; that DNNs can provide informative, abstract distance functions in high-dimensional spaces; and that Innovation Engines can generate a large, diverse, interesting set of solutions in a given domain.
Innovation Engines will only get better as DNNs are improved, especially when generative DNN models trained with unsupervised learning can scale to higher dimensions. Ultimately, Innovation Engines could potentially be applied to the countless number of domains where stochastic optimization is applied. Like human culture, they could eventually enable endless innovation in any domain, from software and science to arithmetic proofs and art.
One way to study a neuron¡¯s different feature facets is to simply perform t-SNE on the real images that maximally activate it. However, doing so does not reveal what a neuron knows about a concept or class. Based on ¡®fooling¡¯ images, scientists previously concluded that DNNs trained with supervised learning ignore an object¡¯s global structure, and instead only learn a few, discriminative features per class (e.g. color or texture). Our work here strengthens later findings showing that, in contrast, DNNs trained with supervised learning act more like generative models by learning the global structure, details, and context of objects. They also learn their multiple facets.
Activation maximization can also reveal what a DNN ignores when classifying. A reason that our method does not always reconstruct a proper facet, e.g. of stuffed peppers, could be that the bell pepper neuron ignores, or lightly weights, stuffing. The number of unique images MFV produces for a unit depends on the k in k-means (here, manually set). Automatically identifying the true number of facets is an important, open scientific question raised, but not answered, by this paper. Overall, we have introduced a simple Multifaceted Feature Visualization algorithm, which (1) improves the state of the art of activation maximization by producing higher quality images with more global structure, details, context, more natural colors, and (2) shows the multiple feature facets each neuron detects, which provides a more comprehensive understanding of each neuron¡¯s function. We also introduced a novel center-biased regularization technique, which reduces optimization¡¯s tendency to produce repeated object fragments and instead tends to produce one central object. Such improved Deep Visualization techniques will increase our understanding of deep neural networks, which will in turn improve our ability to create even more powerful deep learning algorithms.
We have shown that activation maximization¡ªsynthesizing the preferred inputs for neurons in neural networks¡ªvia a learned prior in the form of a deep generator network is a fruitful approach. DGN-AM produces the most realistic-looking, and thus interpretable, preferred images to date, making it qualitatively the state of the art in activation maximization. The visualizations it synthesizes from scratch improve our ability to understand which features a neuron has learned to detect. Not only do the images closely reflect the features learned by a neuron, but they are visually interesting. We have explored a variety of ways that DGN-AM can help us understand trained DNNs. In future work, DGN-AM or its learned prior could dramatically improve our ability to synthesize an image from a text description of it (e.g.by synthesizing the image that activates a certain caption) or create more realistic ¡°deep dream¡± images. Additionally, that the prior used in this paper does not generalize equally well to DNNs of different architectures motivates research into how to train such a general prior. Successfully doing so could enable informative comparative analyses between the information transformations that occur within different types of DNNs.
The most useful property of PPGN is the capability of ¡°plug and play¡±¡ªallowing one to drop in a replaceable condition network and generate images according to a condition specified at test time. Beyond the applications we demonstrated here, one could use PPGNs to synthesize images for videos or create arts with one or even multiple condition networks at the same time. Note that DGN-AM¡ªthe predecessor of PPGNs¡ªhas previously enabled both scientists and amateurs without substantial resources to take a pre-trained condition network and generate art and scientific visualizations. An explanation for why this is possible is that the fc6 features that the generator was trained to invert are relatively general and cover the set of natural images. Thus, there is great value in producing flexible, powerful generators that can be combined with pretrained condition networks in a plug and play fashion.
we revealed that state-of-the-art machine learning models have a serious weakness in which they can be easily fooled by patterns that are visually unrecognizable to humans. This issue is especially worrisome in Deep Learning where we let the agent automatically learn the best strategies to solve a given task. For example, when trained to classify images, convolutional neural networks automatically extract a hierarchy of abstract features that are useful to obtain high performance for the task at hand. Such automatic feature extraction allows deep learning methods to scale well to new problems. However, these methods are not robust enough yet to prevent DNNs from being fooled by unseen data. How to improve model security and reliability (i.e. handling uncertainty gracefully) while enjoying the high scalability remains an interesting, active research area. In addition to revealing the weaknesses of DNNs, the proposed activation maximization methods have also shed light on the set of features learned by each neuron in a DNN. We obtain state-of-the-art visualizations that closely reflect the features captured by a given neuron. However, future research is needed to make our method work equally well on a wide variety of DNNs, including very deep architectures . This would enable researchers to perform comparative analysis across different models. Another open problem is that the activation maximization visualizations for neurons at hidden, fully connected  layers (e.g. layer fc6 and fc7 of AlexNet) are often not human-interpretable. Future work is required to understand the nature of these neurons and whether the representations at such layers are local or distributed. We also turn our visualization framework into an art generation algorithm called the Innovation Engine . This research highlights a success story of combining a many-objective evolutionary algorithm with DNNs. Specifically, the DNN serves as an effective dimensionality reduction tool that maps the high-dimensional search space into a low-dimensional, abstract one where stochastic optimization (here, evolutionary algorithms) is tractable and effective. The Innovation Engine produces interesting images that are not only recognizable by DNNs as familiar objects (e.g. car or elephant), but also rated as art by human judges. The algorithm has been recently applied to evolve 3D objects and could generalize to many other domains as well.
The last research project in this dissertation results in an image generative model called ¡°Plug and Play Generative Networks¡±. In this research, we extend the work described in Chapter 5 by incorporating an additional learned prior, improving both sample quality and diversity. Our method is a state-of-the-art generative model that produces high quality images at a higher resolution (227¡Á227) than previous generative models, and does so for all 1000 ImageNet categories. This work demonstrates the success of harnessing deep features that are learned in a supervised manner to improve generative modeling. Future work is required to fully understand the theoretical underpinnings of such superior empirical results, and generalize them to other domains. In conclusion, my Ph.D. work has contributed to advancing the field of Artificial Intelligence by (1) improving our understanding of deep neural networks; and (2) improving the learning algorithms in the area of evolutionary computation and generative modeling.
The task of texture classification has relevant applications in a wide range of domains, and although being successful in many areas, it is still object of active research with potential to increase classification rates.
We developed a simple method to use Convolutional Neural Networks for texture classification, based on the methods used for object recognition, but taking advantage of the properties particular to texture classification. Our tests with six texture classification datasets demonstrated that this method is able to achieve state-of-the-art results in scenarios where large amounts of data are available, which is the case of many texture datasets (where large images are used).
We also presented a transfer learning method for texture classification using Convolutional Neural Networks, allowing the usage of a dataset from one classification task to improve the classification performance on other tasks. Our experiments with this strategy showed improved accuracy when using datasets from similar tasks. The experiments also demonstrated that this method can be used to improve the performance on tasks where the dataset is very small, by leveraging the knowledge learned by other texture classification tasks, even if they are not very similar.
Future work can explore the optimization of the hyperparameters on the convolutional network (such as number of layers, number of neurons per layer, etc.), since these hyper paramenters were fixed during the experiments on the present work. The strategy to extract patches during testing can also be further explored, experimenting with different strategies such as random patch extraction.
The modulated spiking neural network architecture is in general a powerful architecture capable of solving tasks very efficiently (like the t-maze) by using only a few neurons for a lot of computation. We have also looked into the function of the network for different tasks. However, there are some problems with the network architecture that may hold back its potential.
First the way gas is released in modulated spiking neural networks was borrowed from GasNets. The release of gas had a big influence in GasNets [Hus98] and therefore one assumption was that the release of gas would benefit the network however, because the modulated spiking neural networks work a lot different then traditional networks (like GasNets or CTRNN) due to the spiking neurons, the choice of the gas release function may not be the best one. This problem can probably be solved by finding better conditions for the gas release which are more stable over time. Some possible gas functions may be: Instead of depending on values at one internal step (like charge at one internal step or gas concentration at one internal step) it could be useful to use some kind of ¡°moving average¡± over values (like number of spikes in the last ten time steps or average gas concentration over the last 10 time steps). Another method would be to release gas on spikes and only have a small decay when no spike occurs. The decay must be small enough that the gas is not completely decayed if the neuron has a small period of time without spiking. In addition to that I identified feedback loops as a potential source of problems which can occur when the network is running over a longer period of time, especially if the network does not expect such a long running time. This can be problematic in real world use cases. The problem exists because of the selection of modulation parameter by Stefan Bruhns [Bru15], for which he unfortunately does not give an explanation of his choice. It would be useful to replace them in a way that create biologically meaningful spiking pattern.
After this thesis has analysed the current modulated spiking neural network architecture, the next step would be the improvement of the architecture. Conclusion the replacement of the gas function and the determination of better modulation parameter. However such work would exceed the scope of this bachelor thesis. The source code used in this bachelor thesis can be found at BitBucket or GitHub. See appendix C for more information.  An artificial Neural Network model for predicating student performance in the Department of Computer Science and Engineering was presented. The model used feed forward back propagation algorithm for training. The factors for the model were obtained from student registration records. The model was tested and the overall result was 84.6%. This study showed the potential of the artificial neural network for predicating student performance.
The research herein presented investigates the potential of the NeuCube-based methodology proposed in section 5.2.1 by means of a feasibility study in BCI-based rehabilitation system.
When considering the classification accuracies, which ranged from 70 to 85%, it is important to take into account three factors. Firstly, the data were collected in an unshielded room using a commercially available gaming EEG headset, resulting in an EEG signal with relatively high signal to noise ratio. Secondly, there was no processing or feature extraction performed on the data prior to classification; the raw, noisy EEG data was used as the input. Thirdly, all comparative methods in this study, except NeuCube, were validated using LOOCV, while NeuCube was validated with RRSV, a more disadvantageous 50/50 (half used for training, half for testing) split. The accuracy of NeuCube was still significantly higher than the other techniques and would likely rise when trained using leave-one-out approach.
Bearing these three factors in mind, the classification accuracies obtained using NeuCube are in a similar range to those reported in other research and demonstrates that NeuCube is capable of accurately classifying noisy and relatively low-quality data. In addition, unlike many other approaches, NeuCube does not require a lengthy feature extraction process; instead it use all the raw data for classification, thus utilizing a rich data set that does not lose any potentially useful data. We chose to use a relatively cheap and accessible EEG headset because two major factors that prevent the adoption of high technology interventions into rehabilitation practice are cost and complexity. EEG systems commonly used in research and clinical.
The Emotiv neuroheadset has a limited number of channels with a fixed electrode placement, which may serve to improve usability as it reduces the preparation time and is easy for users to put on themselves. An advantage of the NeuCube is that it allows for interpretation of results and understanding of the data and the brain processes that generated it. This is illustrated in Fig. 5.2 where the connectivity of a trained SNNc is shown for further analysis. The SNNc and the deSNN classifier have evolvable structures, i.e. a NeuCube model can be trained further on more data and recalled on new data not necessarily of the same size and feature dimensionality. This allows in theory for a NeuCube structure to be partially trained on highly accurate data captured in a controlled manner with medical devices, and then further trained and adapted to the particular subject with a cheaper, less accurate device such as Emotiv. This will increase potential uses in clinical and rehabilitation applications.
The large number of parameters that need to be optimized for every experiment to achieve the best results limits the current NeuCube architecture. The results presented in this study are obtained through manual parameter optimization. To mitigate this, adaptive and evolutionary techniques (including the GRN discussed earlier and quantum-inspired optimization) are being developed for this system, so that parameter selection is automated in a desirable way.
The NeuCube constitutes a brain-inspired three-dimensional architecture of SNN foron-line learning and recognition of STBD. It takes into account the spatial coordinates of the sources of the STDB using a standard brain-template, offering a better understanding of the information and the phenomena under study.
The goal of this study has been to develop a method for the analysis of the connectivity and the dynamic activity of a NeuCube model trained on EEG STBD in order to understand changes in brain activities across different subjects and different groups of subjects undertaking different treatments. Traditional data mining/machine learning algorithms are not able to properly deal with this kind of data. Our results demonstrated that a NeuCube model can not only achieve a better sensitivity and specificity when classifying EEG data when compared to traditional AI methods, but it is also interpretable for a better understanding of the EEG data and the processes that generated it. This makes the NeuCube modelling approach widely applicable for neuroscience research across data and problems.
The goal of the proposed study has been to develop a personalised model able to properly learn over time epileptic events in terms of space and time, so that the information can be dynamically visualised and analysed and possibly the epileptogenetic events predicted.
Our results demonstrated that the methodology constitutes a valuable tool for epileptic EEG data analysis and understanding. However, more extensive evidence is needed to establish the feasibility of a purely data driven diagnosis method for CAE diagnosis. So far, our results are promising and the proposed NeuCube-based methodology is planned to be used for molecular and genetic analysis of the disease and as a personalised model for the understanding of functional changes in the brain and for the prediction of epileptic events from new data.
More specifically, we propose the methodology to be used to CAE data to study how the regulation of GABA-mediated inhibitory mechanisms, which are believed to
be involved in the neural hyper-syncronization responsible for type of epilepsy, can affect the post synaptic potential of a neuron. This type of mechanisms are mediated by pharmacological treatments and we believe the NeuCube-based methodology could be of great help to clinicians for the analysis of possible changes in neural connectivity.
Also, NeuCube can be used for dynamic predictive modelling based on neuromorphic learning. The acquisition of more CAE data and their comparison to data from healthy
subjects can be used to create such model that learns the progression of the epileptic events of a person over time. The brain-like mapping of the cube can be used to Chapter 9. NeuCube-Based Methodology for Stepwise Connectivity and Spiking ctivity Analysis 165 study the specific characteristics of the epileptic events, the area of the brain where the event occurs and eventually to predict future epileptogenetic events based on the initial information.
The proposed NRDP learning rule has been successfully applied here on integrate and-fire spiking neurons for modelling their synaptic plasticity by means of dynamic
changes in neuroreceptors activity. According to the obtained results, the NRDP learning rule can be viewed as an extension of the STDP rule, as it can be used to achieve similar spike timing as the STDP through a suitable selection of the neuroreceptor parameters.
Additionally, the NRDP rule can be implemented in a NeuCube SNN architecture to create a NeuCube-NRDP system for computational neurogenetic modelling. This system would allow to model EEG and other brain data, but more importantly, it would allow to study the impact of the neuroreceptors on the machine learning of the data and to further interpret the findings for the study of brain conditions. Targeting these molecular mechanisms could form the basis for new therapeutic strategies for the treatment of mental diseases since glutamate and GABA receptors are essential for many important physiological functions. To draw more conclusions, the NeuCube-NRDP model needs to be applied on EEG data to study the model behaviour, the resulting classification and connectivity or spiking activity outputs.
It is rather difficult to find studies where all these challenges are taken on. Proposed models often fail due to the lack of biological details and therefore have insufficient ability to represent the phenomena being studied. Also, STBD, the most commonly collected data for the study of brain behaviours, are often mined with techniques that suffer from loss of details and patterns, which leads to incoherence in the analysis of results.
Driven by this problematics, we have investigated the development of a new biologically plausible SNN methodology for spatio-temporal EEG data modelling, classification and understanding . The research extended further into the creation of an additional methodology for the analysis of connectivity and spiking activity generate in the SNN model with the aim of understanding functional changes in brain activity generated by the available spatio-temporal information (Chapter 8). Additionally, a new unsupervised learning rule has been proposed to better deal with the data and to investigate the biological processes responsible for brain synaptic activity to target pharmacological treatments.
As part of the research objectives, we explored the potentiality offered by eSTDM NeuCube architecture to develop new biologically plausible methodologies for modelling and understanding EEG data and the neurological events that generate it. This is important. Further improvement of the understanding and use of the proposed methodology would contribute to the advancement on IS research for the prediction and understanding of brain data and more specifically for data related to neurodegenerative disorders, such as AD. NeuCube constitutes a biologically inspired 3D environment of SNN for on-line learning of spatio-temporal brain data and recognition of patterns within the data. It takes into account data features, offering a better understanding of the information and the phenomena of study. The proposed methodology is based on the NeuCube architecture and has demonstrated to be capable of accurately classifying even noisy and relatively low-quality data. An advantage of the NeuCube-based methodology is that it allows for interpretation of results leading to understanding of the data and the brain processes that generated it. NeuCube could be partially trained on highly accurate data captured in a controlled manner with medical devices, and then further trained and adapted to a particular subject, which will increase potential uses in clinical applications allowing to trace the development/decline of cognitive processes over time and to extract new information and knowledge about them.
This research explored and proposed a new unsupervised learning rule for SNN, called NRDP where the synaptic plasticity is modelled based on neuroreceptors dependent plasticity. The proposed NRDP learning rule has been successfully applied on LIF neurons by achieving similar classification results as the STDP rule. Additionally, it offers the possibility of modelling dynamic changes in neuroreceptors synaptic activity. This could be further studied by means of a NeuCube-NRDP system for computational neurogenetic modelling. The NeuCube-NRDP model allows mining of STBD to study the impact of neuroreceptors activity on the PSP of the neurons and further interpreting the findings for the study of brain conditions. This could potentially help the understanding of molecular mechanisms involved in neurodegeneration and treatments of neurological disorders.
So far, two constant learning rate training schemes can not guarantee convergence. Backtracking training scheme, backtracking noised training scheme, and decaying learning rate noised training scheme can converge to stationary point in different forms.
This work have implemented CNNs compression with CP decomposition, Tensor Power Method, and iterative fine-tuning. Those steps are important to achieve high compression rate with all layers decomposition and solve CP instability problem to recover the accuracy. In addition, as finding rank in tensors for the decomposition is NP-hard, we have proposed several rank selection techniques, from sensitivity (loss ratio), number of parameters ratio, and VBMF and showed their effectiveness. Sensitivity shows better performance for whole network decomposition. However, the sensitivity method is still arbitrary in selecting the average rank. The restored accuracy shows that iterative fine-tuning can solve the CP instability problem. We have demonstrated the proposed method by deploying AlexNet, GoogleNet, and VGG16 in Android device.
Deep learning is a set of powerful machine learning algorithms and concepts with groundbreaking success for the last ten years. The main benefit of deep neural networks are their ability to learn complex non-linear hypothesis without the need of explicitly modeling features, but rather learning them from data. Convolutional networks allow to handle distortions, such as translation and rotation in the input, which occurs frequently in computer vision. Applied to action unit recognition and smile recognition in particular, a deep convolutional neural network model with an overall accuracy of 99.45% significantly outperforms existing approaches with accuracies ranging from 65.55% to 79.67%. The network parameter values are subject to extensive model selection. Various variations of this experiment are run, such as retaining less neutral images or only high or low intensities or classifying into low or high intensities. For all experiments, very high accuracies above 98.90% are achieved, too.
Choosing the entire face as input or just the mouth only led to minor differences in the accuracies, not generally favoring either input. The proposed temporal part using LSTMs was not implemented due to the high accuracies achieved. It would however be interesting to implement it in the future in order to predict smiles in image sequences. There are many further topics worth to be investigated. For example, instead of one CNN being trained on the entire face or the mouth, multiple CNNs could be trained on different regions of the face. Possible regions are the mouth, the nose and both eyes. A specialized CNN could be trained for each region allowing to generalize better because of the lower number of parameters in each network. 
The CNNs can then be combined using a Shape Boltzmann Machine [9]. Furthermore, in order to understand the networks better and to do informedly better than blind model selection, it would be interesting to visualize the units of a network to understand what they learned to detect. This can help to work well on a variety of action units other than smile. In this thesis, the mouth was compared to the entire face, for which no significant difference was detected. It would however, be interesting to investigate this more by comparing the mouth to the face excluding the mouth. So far, the existing model has been used for classification. In a next step, it can be adopted to regression of action unit intensities or even valence-arousal [43]. To date, stochastic gradient descent is the preferred training algorithm for neural networks, as discovered by LeCun in the 1980s and 1990s [31]. Overall, stochastic gradient descent performs well on deep neural networks, yet it would be interesting to investigate if LeCun¡¯s observation still holds for deep neural networks. Therefore, stochastic gradient descent should be compared to a variety of other optimization algorithms, such as Gaussian Newton or Quasi Newton methods when training deep neural networks.
The objective of this master thesis was to present the state of the art in deep neural networks design: understanding the need of deep architectures, discussing related topics, and studying the most prevalent types of deep neural networks.
Another objective is to develop an implementation of the discussed deep neural network models that will be used to perform the master thesis experiments and will be building block for further studies and experiments. Also, we wanted to reproduce experiments similar to those in the literature: compare experimentally which architectures perform better at each combination of number of units per hidden layer in the case of reconstruction, and number of hidden layers, units per hidden layer, and initialization algorithm in the case of classification.
As we have seen, the advanced random initialization for the multilayer perceptron gives good results, and is an interesting improvement that has trivial computational cost and is easy to implement. The greedy layer-wise pre-training algorithm, both using autoencoders and restricted Boltzmann machines, seems a more complex alternative. However, it also gives good results and is interesting from the theoretical point of view of being totally unsupervised and probably related to the mechanisms employed in human learning.
The experiments performed in this master thesis are limited due to the lack of hardware powerful enough to run a big network. The effect of a longer learning, with more epochs and training patterns, and with higher dimensional data and wider hidden layers remains unchecked, and possibly the results would be greatly affected by changes to these parameters.
As future work, the first objective is to develop an efficient implementation to deal with large problems, like complete MNIST or CIFAR. We suggest an implementation of the algorithms in a map-reduce form, which will give us the opportunity to run ex periments in computer clusters, with the consequent improvement in computational power. Some advances have been made in the last months in terms of theory, scale and complexity of the deep networks. Also, we could study the effect of combining the algorithm for the selection of the connections in a receptive field with the greedy layer-wise pre-training used in stacked autoencoders or deep belief networks, which could simplify the training complexity and is also interesting from the biological point of view as it evokes the columns found in the visual cortex.
Another proposal is to use some evolutionary strategies like CMAES that could be interesting to improve training, specially when the error function has many suboptimal solutions, or when the training algorithm is stochastic, like in Boltzmann machines. Apart from classification problems, the use of deep networks for other applications like regression and modeling time series should be studied.
Distributed learning has received considerable attention over the past years due to its broad real-world applications. It is common nowadays that data must be collected, stored locally and data exchange is not allowed for specific reasons, such as technological bottlenecks or privacy concerns. In such a circumstance, it is necessary and useful to build in a decentralized fashion an ANN model. Motivated by this, throughout this thesis we have put forth multiple algorithms to such end. Initially, we have explored extensions to the DL setting of the well-known RVFL network (Chapters 4-6). As in the centralized case, distributed RVFL networks are able to provide strong nonlinear modeling capabilities, while at the same time allowing for a fast and simple set of training algorithms, which are fundamentally framed in the linear regression literature. Thus, they provide a good compromise between a linear model and more complex nonlinear ANNs, such as distributed SVMs.
The successive chapters have considered the more complex problem of distributed training in the presence of labeled and unlabeled data, thus extending the theory of SSL [ 29 ]. This is a relatively new problem in the literature, with a large set of possible real world applications. In this sense, the two distributed models explored in Chapters 7 and 8 are only initial explorations of a field which can potentially reveal much promise. Finally, in the last part of the thesis we have been concerned with learning from time-varying data. Although this is a well-known setting, both of the algorithms that we presented are relatively novel. Indeed, Chapter 9 has introduced one of the first available algorithms for training recurrent networks, while the diffusion SAF in Chapter 10 can be seen as a general nonlinear extension of the much celebrated D-LMS.
Below we provide a set of possible future lines of research, which refer to specific portions of the thesis, along with the main content of each chapter.we have detailed distributed algorithms for learning a RVFL network, in the case of batch and online learning, both for HP and VP partitioned data. In Chapter 5, in particular, we have focused on the application to multiple distributed music classification tasks, including genre and artist recognition. These problems arise frequently in real-world scenarios,including P2P and mobile networks. Our experimental results show that the proposed algorithms can be efficiently applied in these situations, and compares favorably with a centralized solution in terms of accuracy and speed. Clearly, the algorithms can be successfully applied to distributed learning problems laying outside this specific applicative domain, particularly in real-world big data scenarios. Moreover, although in Chapter 5 we have  focused on local updates based on the BRLS algorithm, nothing prevents the framework from being used with different rules, including efficient stochastic gradient descent updates. We have proposed a totally decentralized algorithm for SSL in the framework of MR. The core of our proposal is constituted by a distributed protocol designed to compute the Laplacian matrix. Our experimental results show that, also in this case, the proposed algorithm is able to match efficiently the performance of a centralized model built on the overall training set. Although we have focused here on a particular algorithm belonging to MR, namely LapKRR, the framework is easily applicable to additional algorithms, includingthelaplacianSVM(LapSVM)[ 11 ], andothers. Moreover, extensions beyond MR are possible, i.e. to all the methods that encode information in the form of a matrix of pairwise distances, such as spectral dimensionality reduction, spectral clustering, and so on. In the case of kernels that directly depend on the dot product between patterns (e.g. the polynomial one), particular care must be taken in designing appropriate privacy-preserving protocols for distributed margin computation [ 164 ], an aspect which is left to future investigations. Currently, the main limit of our algorithm is the computation time required by the distributed algorithm for completing the Laplacian matrix. This is due to a basic implementation of the two optimization algorithms. Inthissense, infutureworksweintendtoimprovethedistributed algorithm to achieve better computational performance. Examples of possible modifications include adaptive strategies for the choice of the step-size, as well as early stopping protocols.
We have solved the problem of distributed SSL via another type of semi-supervised SVM, framed in the transductive literature. Particularly, we have leveraged over recent advances on distributed non- convex optimization, in order to provide two flexible mechanisms with a different balance in computational requirements and speed of convergence. A natural extension would be to consider different semi-supervised techniques to be extended to the distributed setting, particularly among those developed for the S 3 VM [28]. We have introduced a decentralized algorithm for training an ESN. Experimental results on multiple benchmarks, related to non-linear
system identification and chaotic time-series prediction, demonstrated that it is able to efficiently track a purely centralized solution, while at the same time imposing a small computational overhead in terms of vector ? matrix operations requested to the single node. This represents a first step towards the development of data-distributed strategies for general RNNs, which would represent invaluable tools in real world applications. Future lines of research involve considering different optimization procedures with respect to ADMM, or more flexible DAC procedures. More in general, it is possible to consider other distributed training criteria beyond ridge regression and LASSO (such as training via a support vector algorithm) to be implemented in a distributed fashion. Finally, ESN are known to perform worse for problems that require a long memory. In this case, it is necessary to devise distributed strategies for other classes of recurrent networks, such as LSTM architectures.We have investigated a distributed algorithm for adapting a particular class of nonlinear filters, called SAF, using the general framework of DA. The algorithm inherits the properties of SAFs in the centralized case, namely, it allows for a flexible nonlinear estimation of the underlying function, with a relatively small increase in computational complexity. In particular, the algorithm can be implemented with two diffusion steps, and two gradient descent steps, thus requiring in average only twice as much computations as the standard D-LMS. Our experimental results show that D-SAF is able to efficiently learn hard nonlinearities, with a definite increase in convergence time with respect to a non-cooperative implementation. In the respective chapter, we have focused on a first-order adaptation algorithm, with CTA combiners. In future works, we plan to extend the D-SAF algorithm to the case of second-order adaptation with Hessian information, ATC combiners, and asynchronous networks. Additionally, we plan to investigate diffusion protocols for more general architectures, including Hammerstein and IIR spline filters. 
A few general considerations on the thesis are also worth mentioning here: Fixed topology: for simplicity, in this thesis we have supposed that the network of agents is fixed, and connectivity is known at the agent level. This is not a necessary condition (indeed, many practical applications might require time-varying connectivities), and work along this sense is planned in the near future. Indeed, many of the tools employed throughout the thesis, e.g. ADMM, already possess extensions to this scenario, which can in principle be applied to the problems considered here. 
Synchronization: similar considerations apply for the problem of having synchronized updates, requiring a general mechanism for coordinating the agents. Investigations along this line can start by considering asynchronous versions of SGD [119], or DA [204].
Specific ML fields: another important aspect is that, similarly to SSL, many subfields of ML remain to be extended to the distributed setting. As an example, there is limited literature for distributed implementation of active learning strategies [ 179 ], where agents are allowed to request a set of labels on items that they assume to be interesting. This can potentially reduce drastically the training time and the amount of communication overhead. 
Multilayer networks: we have investigated distributed methods only for ANN having at most one hidden layer of nonlinearities, which are known as ¡®shallow¡¯ in the current terminology. Indeed, we saw in Section 3.4.7 that investigations on distributed deep neural networks have been limited. This is due to the large number of parameters to be exchanged, and to the resulting non-convex optimization problem. Both these problems require additional investigations in order to be properly addressed.
Additional distributed techniques : finally, we expect that techniques originally developed for distributed signal processing and distributed AI might be applied to the problem of DL, resulting in beneficial effects in term of in-network communication and/or computational requirements. This is the case, for example, of message censoring, a set of techniques allowingeach individual agent to decide whether to take a specific measurement and propagate it over the network.
In this thesis topology and weight evolving neural network system NEAT was examined in detail. As published articles do not contain all necessary information I had to study also source codes of several NEAT implementations. The outcome of this is the detailed description of NEAT containing also undocumented features.
The second step was a creation of my own NEAT implementation to get a reliable platform for further experiments and NEAT algorithm modifications. Java programming language was chosen, because Java is portable and it was also used for neural simulators developed in the Department of Computers. Soon after implementation I have performed a series of tests on XOR classification and Double Pole Balancing No Velocity (DPNV) problems in order to reproduce the results published by Stanley, the original creator of NEAT. My measurements have shown that although my NEAT implementation was able to solve both tasks (even the very difficult DPNV) the results were much worse than those published. It needed much more time to optimize networks, it was very unstable and in many cases it even failed to find a solution. To find the source of problems I have implemented the visualization showing the evolution of species during speciation. I have found the instability caused by explicit fitness sharing (EFS) speciation algorithm, the core of the NEAT. I have decided to replace it by another speciation system the deterministic crowding. The outcome was a NEAT modification called DC NEAT. The same series of experiments was performed. I observed a remarkable improvement. The results were much rather close to those reported by Stanley, although not always as good. Plus algorithm shown to be very stable consistent in number of generations needed to optimize and topology sizes evolved. I have also designed and implemented a visualization similar to the one described above; it has again confirmed the stability of algorithm. Soon after these experiments I have found an error in my previous EFS implementation, after its correction, all experiments were repeated once again. I was not able to repeat Stanley¡¯s results for XOR classification, on the other hand, DPNV tests turned out well. DC NEAT performed better on XOR but was worse on DPNV. DC NEAT was shown to be superior to classic NEAT in stability. It is is also simpler - less parameters are needed to set it up. Foremost, the distance threshold which affects the number and composition of species is always difficult to set up. DC NEAT development brought a new alternative to the current (EFS) NEAT. It cannot be told which is better, it seems this may differ from task to task. Probably the best practice would be to test both when solving a specific problem. In another set of experiments I have found that link innovation history list which is an integral part of classic NEAT does not improve NEAT¡¯s performance at all and thus it can be removed in order to simplify NEAT.
To test NEAT¡¯s ability to optimize large networks I have tried to solve the so-called Spiral classification problem but with no greater success. This has shown NEAT¡¯s weakness in solving problems which assume large networks. The second experiment was performed on a real world problem: mandarin tree data set, in which water consumption is predicted. Resulting neural networks accomplished this with sufficient accuracy. Two versions of recurrent neural network visualizations were developed: 2-D and 3-D. They may be used not only for presentation purposes, but also to understand how neural network works inside. Both visualizations are simply separable from my NEAT implementation and thus can be used in other recurrent neural network systems.
As we have seen in this work NEAT fails on high-dimensional tasks (long genomes). One possibility to make it work better is to change the genetic encoding somehow in order to support already evolved structure reuse. It seems that many tasks may be solved by networks which contain many approximate copies of the same simpler structure. This can also be seen in nature, for example in the parts of brain which process the vision. Stanley suggests that some indirect encoding, like cellular one, may be a good start.
Another approach which may possibly deal with the ¡±curse of dimensionality¡± also deals with reusing structures. The idea of reusable building blocks is applicable only for tasks which can be manually divided into smaller sub-tasks. Those subtasks can be solved separately. Then evolved networks of all subtasks would be put together and NEAT would be used to evolve an interconnecting network between them. In other words subtask networks would be viewed at as special types of neurons with fixed number of inputs and outputs. Using these ¡±special¡± neurons and classic neurons a network for the whole task may be constructed. This should improve solvable task dimensionality.
For example let us imagine we are evolving a neural network for controlling a simulated robot. Such task can be very complicated and probably large networks will be employed. Luckily it can be also divided into smaller and simpler sub-tasks. First sub-task may be the controlling of robot movement - we will train a network to translate simply encoded commands like go to coordinates (x, y) to actual signals for controlling robot¡¯s motors. Second sub-task may be the processing of input sensors data. Third may be the manipulation with objects. These tasks will be solved separately using simple training procedures. For example the fitness function for the first sub-task may correspond to the time needed to move robot from some random coordinates to other. After having these tasks solved, NEAT will evolve neural network interconnecting them and robot¡¯s inputs (sensors) and outputs (motors etc.) to solve the main, much more complex task, such as for example: seek for an object of type A, go to it, grip it, go back to original position, and drop it.
Three different classes of gas price prediction models are examined in this study to determine the optimum model. Introducing exogenous variables is proposed as a viable approach towards accurate price prediction. However, the results in this study indicate that the accuracy in the prediction is not significantly improved by introducing exogenous variables. Moreover, the price spike characterization is not improved despite the increased complexity of the model due to exogenous variables. Therefore, the univariate models may sometimes be selected due to their simplicity as compared to the complex multivariate models.
It is shown in the modeling result that the appropriate number of the lags for the model is 9, particularly in the autoregression models. Due to the seasonality nature of the natural gas price, which is a function of consumption, the cycle is expected to match the calendar cycles, namely, seasonal (3 months) or annual (12 months) periods. The results indicate that, the NAR neural network provides a better fit to the given data as compared to the other proposed models. The three-layer NAR model with 6 hidden neurons was found to have the best performance in terms of one step ahead price prediction. The accuracy of the NARX model with 6 neurons is found to be higher than that of the other models. Although, this model provides a reasonable fit to the given data, it fails to capture the price spikes effectively.
The sensitivity analysis shows that CDD/HDD temperatures, extreme minimum temperature, and WTI oil prices have an insignificant effect on the results. On the other hand, total consumption, total production, and mean weather temperature impact the results significantly.
In this chapter, we have made a literature review of IoT technologies and it¡¯s application in agriculture domain. We studied the network architecture, standards
and protocols of IoT and selected the best communication protocols for our further IoT designs. Moreover, we studied and analyzed latest technologies in telecommunication systems. Considering that in agriculture domain we need long distance communication and power efficient technologies, we proposed the best WSN technology. In next two chapters, we will discuss developed short-range IoT application using BLE and long-range application using WiFi protocols.
In this chapter, we introduced a wireless sensor device designed with low power components, which collects physical data through BLE technology and sends it to a BLESensor application developed on Android Studio[ 59 ]. Further, acquired data, which is in .xml extension and XML data format can be sent via e-mail for data analysis. In this sense, our portable devices could be useful to send acquired data to the Internet as the part of IoT application. Experiments and tests using a climate chamber and applying various environmental conditions on it, allowed us to determine the accuracy of the sensor node. Simultaneously, we tested the power consumption of the device during each condition to determine if the changes in environmental conditions alter the power consumption in any way. The obtained data were used to calculate the battery life of the sensor node. Power consumption of the system was future research work in this paper [ 34 ] and we introduced only sensor node. Afterwards, we published another paper [ 60 ] with all information of the sensor node including: hardware and software design, android application design and algorithm, experiments on the climatic chamber (Angelantoni ¨C Challenge 250) to calibrate the sensor, calculation of power consumption and battery life of the BLESensor node.
Next research field will be on Network topology for BLE. This is an area of interest because billions of sensors and actuators [ 61 ] will be deployed in the next few years and an emerging trend is to connect sensors with the Internet of Things (IoT). The low-power radio technology has perhaps the highest potential for IoT use. The application which is still lacking IP capability is BLE which is expected to be incorporated in billions of consumer electronic devices around the globe. Accordingly, the capability to run IPv6 over BLE opens new doors to the IoT and promotes BLE towards new application areas. The most important research of these areas would be to exploit the smartphone as a gateway for providing Internet connectivity to surrounding BLE enabled sensors. For instance, this approach allows one to remotely and ubiquitously monitor medical parameters from body sensors. Another example of the use of this application is with vehicle health messages, which can be sent by vehicular sensors through the smartphone of the driver to remote Intelligent Transportation System (ITS) control centers in order to prevent accidents. Similar applications can be found in other domains including home, urban and industrial automation. Furthermore, enabling IPv6 over BLE contributes to interoperability between IoT devices that utilize different low-power radio technologies. This is particularly important since Internet Engineering Task Force (IETF) standardization work is currently progressing towards extending the family of low-power technologies with IPv6 support. Other experiments have been proposed with the goal of implementing different learning machine tools in Wireless Sensor Networks in order to predict a sensor data will also be investigated. In conclusion, the use of BLE technology with our Android system can reduce power consumption on the whole system. In the next chapter, we will talk about implementation of WiFi technology and smartphone to monitor plants from the long distance.
The development of BLESensor and IoP systems has met all the technical specifications of the initial parameters of the project. Important parameters such as the maximum communication distance, the power consumption and the BLESensor node lifetime have been measured and verified leading to a satisfactory result. The humidity and temperature sensors have given excellent results in terms of accuracy. In the future, Android Application interfaces could be used to control air conditions in greenhouses. Additionally, we compared two technologies of IoT world, for a long distance and for short distance applications. Developed Sensor nodes can be a part of the IoT. Moreover, the low cost of high stack components order makes it attractive for a possible sale on the market. All of the obtained features makes it a suitable WSN and IoT based system, with the aim of achieving goals of smart agriculture. The same idea could be applied in different integration scale: a number of miniatures, lightweight and ultra-low power devices can be integrated into the so-called Wireless Body Area Network (WBAN) for health monitoring or can be applied in an Environmental Wireless Sensor Network (EWSN) to accurately monitor the surrounding physical phenomena. Since data collection takes a long time in agriculture applications we used OAK data set to study predictive models. We used ANN to predict environmental data. We applied NNARX model for one step ahead prediction. The model performed as expected compared to other models and we used the same model to predict 10-days-step ahead for maximum and minimum temperature and results were satisfactory. In our case, ANN is applied only in engineering field but the same developed predictive neural network model could be used and applied also in different fields such as finance, cognitive psychology/neuroscience, medicine, and physics as well. In conclusion, as already mentioned above, this work must be intended only as a proof-of-concept, although, the developed BLESensor system, IoP prototype device, and predictive models showed expected optimum results, both in terms of functionalities and usability.
In this thesis, the importance of markets forecasting for a naive customer who does not have a sufficient information to enter the securities market, the ability to discover numerical models, which is able to reliably forecast the route of the future stock prices, academics, traders, and trading experts are always looking for a stock market model, which could gain them with higher earnings and how to use the other data mining techniques as classification; pattern matching, etc. using evaluating previous events, a prediction can be made by us for future. Forecasting or prediction means discovering the future knowledge based on past knowledge. As an example mixture of decision tree analysis of every historical data with classification and previous pattern, matches are being used to recognize the next following day's opening price of the stock market, using closing prices and a past day's opening. The artificial neural network (ANN) model utilizes their indexes as input parameters to find the rules that describe the change of indices by the dependence of the change of closing price utilizing the training data set, we determine several conclusions; the main of these revolves around the existence of statistical value in the probability of reliance on these indicators along the way of prediction. The trend of stock prices for the bank sector detailed in the Iraqi market for securities to be modified to the circumstances of the Iraqi environment. This study completes recommendations that urged traders to improve perception and knowledge of technical analysis, and the necessity for diversification in the utilization of technical analysis methods prior to making a financial decision, and urged academia enhance focus on the technical analysis using motivating study and researchers.
In the future works, we plan to use adaptive and predictive control theory, it may represent a good method to approximate the daily changes of any stock market, especially Iraqi market. Also, we are planning to achieve the same idea as a final product (Android, iPhone or Microsoft based application).
Although neither the output of the neural network is the final objective of our model nor the implemented network follows the usual standards of artificial neural networks, formulating our problem in terms of training a neural network allows us to profit from advanced techniques developed in this area such as backpropagating the error gradients with AdaGrad, which is known for being specially suitable for very sparse data such as natural language documents.
Hyper-parameter tuning is a general pitfall of neural network based models. This is in line with the need to define the number of neurons per layer in the case of the standard multilayer perceptron formulation. However, in our approach this problem becomes even harder due to a high number of hyper-parameters to determine despite fixing those values mentioned in. If we had had to perform an exhaustive grid-search on all the hyper-parameters, our search method would have taken even longer to find acceptable hyper-parameters. We could not reproduce the results claimed in [ 46 ], perhaps because of the difficulty of finding good hyper-parameters. We only observed a performance comparable to the continuous skip-gram model.
Despite some relative good results evaluating specificity of the words, they only take place in few embedding sets and they always include considerable ¡°noise¡± within the sorted words by variance. This may be caused by not enough tuned hyper-parameters as well or because we should configure a validation set where the variances play a more important role. But again, the potential advantages of adding variance to word vectors cannot be exploited if good hyper-parameters are so hard (and time-consuming) to find.
We could also visualize some interesting linguistic relations among our word embeddings by applying kernel PCA. The meaning of the positions of the distribution means was quite evident in the presented examples, but the plotted variances were only sometimes informative. This is for us another signal that the variances are the weak spot of our embeddings.
Regarding our software implementation, the training speed can be still improved by approximating the energy function calculation with a precomputed table in a similar way word2vec does. Also the weight updates could be optimized through a more efficient algorithm e.g. by using hash tables instead of storing all the mini-batch updates in a large array of length the size of the vocabulary. If we continued our work, we would try to find hyper-parameters with a different validation test. In particular, we would check whether calculating similarities with EL similarity instead of cosine distance during validation would result in more informative variances of the Gaussian embeddings.
To sum up, inserting an uncertainty measure to word vectors via multivariate Gaussian distributions enables some new possibilities such as determining the specificity of a word compared to similar ones. However, a long process of hyper-parameter tuning is required to achieve any acceptable result. Therefore, the few advantages from this model are, in our opinion, not worthy the increase of complexity compared to the continuous skip-gram model.
To the best of our knowledge, this thesis corresponds to the first attempt in training a computer program to play chess, while not making use of any lookahead algorithms to play the game at a high level. All the information that has been presented in this work aimed to investigate if this research challenge could actually be accomplished. The results that have been presented show how it is indeed possible to make use of Artificial Neural Networks (ANNs) to train a program that is able to evaluate chess positions as if it would be using lookahead algorithms. However, the system that has been presented is still far from the strongest existing chess engines and best human players. Nevertheless, the level reached by the best performing ANNs is still remarkable since it reached an Elo rating of ¡Ö 2000 on a reputable chess server 1. The ANN played in total 30 games according to the following time control: 15 starting minutes are given per player at the start of the game, while an increment of 10 seconds is given to the player each time it makes a move. The ANN played against opponents with an Elo rating between 1741 and 2140 and obtained a final game playing performance corresponding to a strong Candidate Master titled player. The games show how the ANN developed its own opening lines both when playing as White and as Black and performed best during the endgame stages of the game, when the chances of facing heavy tactical positions on the board are very small.
The chess knowledge that it learned, allowed it to easily win all the games that were played against opponents with an Elo rating lower than 2000, which correspond to ¡Ö 70% of the total games. However, this knowledge turned out to be not enough to competitively play against Master titled players, where only 2 Draws were obtained. We report one of the most interesting positions that the ANN faced while playing on the chess server. The ANN, playing White, won this complicated endgame in which, even though Black has an advantage of one Knight, it managed to promote one of its pawns to Queen. The situation on the board presented in the figure is particularly interesting. Black is checking White¡¯s King with the Bishop, hence White plays Kxh5. After this move, Black has again the chance of checking White with the move Be2+. White moves its King back to g5, where it gets checked again by Black¡¯s Bishop in d3. This is a crucial moment in the game, since if White would go back to h5 Black would be able to get a Draw by repetition. 
Even though the ANNs managed to play chess at a high level without making use of looka head algorithms at all, the chess knowledge they learned from the databases that we described, turned out not to be enough to win against Master titled players. During these games the ANNs lost most of the games already during the middle game when, due to tactical combinations they lost material on the board. As also supported by the results obtained on the Kaufman Test presented, it seems that in order to completely master the game of chess some lookahead is required. Hence we believe that the most promising approach for the future will be to combine the evaluations given by the current ANNs together with quiescence and selective search algorithms. By doing so the ANNs will be able to avoid the horizon effect and also perform well on tactical positions.
Secondly it could be possible to improve the performance of the ANNs through the use of Reinforcement Learning (RL). Mastering a board game by making use of RL from scratch can be very hard. In fact, a lot of exploration is required before finding a good game playing policy. Our system provides a solution to this issue since it has already learned a lot of chess knowledge that allows it to play the game as a Candidate Master. Furthermore, since this input representation has only been used on CNNs, an interesting future idea would be the one of representing the same information more efficiently. In such a way also MLPs could benefit from it.
The subject of this thesis is to advance in dataset modeling via competitive learning where data samples are weighted by a magnitude that does not necessarily correspond with data density.
I proposed a set of Magnitude Sensitive Competitive Neural Networks (MSCNN) that work like usual competitive learning neural networks in vector quantization tasks, but include a target magnitude function. The effect of this factor is to force units to concentrate in zones of high value of the desired target function, calculated locally from the data or unit parameters. MSCNNs differ from other standard Competitive Learning algorithms that usually generate a discrete approximation to data probability density-function. As a result, MSCNNs are more versatile to distribute prototypes following any property or characteristic of the data. The application examples showed MSCNN capabilities in different applications: Gaussian distribution quantization, data series interpolation, surface modelling from 3D point clouds, color quantization and selective image compression. The comparative results with other competitive methods have validated advantages of MSCNNs in those tasks where the desired codebook distribution does not correspond to the data density distribution.
We present a generalization of mean-field interacting Hawkes processes, namely age dependent random Hawkes processes (ADRHPs), which are well-adapted to neuroscience modelling. From a biological point of view, they encompass some interesting features such as refractory period, synaptic integration or random synaptic weights. These processes are studied in a mean-field situation and we show in Theorem 3.4.1 and Corollary 3.4.5 that, as the number of particles goes to infinity, they can be well approximated by point processes of the McKean-Vlasov type whose intensity depends on time and on the age. These limit point processes are closely related to the age structured PDE system introduced by Pakdaman, Perthame and Salort, namely (PPS). Hence, using the theory of mean-field approximations, the present article makes a bridge between the microscopic modelling given by Hawkes processes, or more generally age dependent random Hawkes processes, and the macroscopic modelling given by the (PPS) system. This bridge is presented under the main assumption that the intensity of the microscopic point processes is bounded. In this sense, the present article offers an answerto the question left open in the previous chapter. This legitimises the convolution term X(t) in the (PPS) system as well as opens the way to the study of new assumptions on the 108 3. MEAN-FIELD LIMIT OF GENERALIZED HAWKES PROCESSES spiking rate p appearing in the (PPS) system from a more analytical point of view. Up to our knowledge, this has not been done yet. The present article gives somehow the law of large numbers for a generalization of Hawkes processes. It could be interesting to investigate how these processes fluctuates around their mean limit or in other words find some kind of functional central limit theorem for Hawkes processes in a mean-field framework. As noted, random synaptic weights can be considered in this study. However, they are supposed to be, in some sense, independent and identically distributed which can be considered as an unrealistic assumption. Inspired by [48], it could be interesting to see how correlated synaptic weights could be handled in the Hawkes processes framework. On a different path, it could be interesting to see how locally stationary Hawkes processes, as introduced in [143], behave in a mean-field situation. Indeed, these processes may take into account the dynamics of the synaptic weights occurring in the neural network.
Under the hypothesis that the point processes are homogeneous Poisson processes, the expectation and variance of the delayed coincidence count can be computed, and then a test with prescribed asymptotic level is built (Theorem 5.3.3). A simulation study allows us to confirm our theoretical results and to state the empirical validity of our test with a relaxed Poisson assumption. Indeed, we considered Hawkes processes which are a more realistic model of spike trains. The simulation study gives good results, even for small sample size. This allows us to use our test on real data, in order to highlight the emergence of a neuronal assembly involved at some particular time of the experiment. 
We achieved the full generalization of the single test procedure introduced in [158]. However, we could not achieve the multiple time windows testing procedure mainly because of the default of Gaussian approximation concerning extreme values of the test statistics. More precisely, very small p-values are not distributed as expected. In particular, as noted at the end of Section 5.4.a), when the sample size M is moderate (M = 50), our test returns too many very small p-values. In [158], the MTGAUE method is applied simultaneously on 1900 sliding windows. In the present work, in order to apply multiple testing both with respect to the sliding time windows and the subsets, the total number of tests is even larger.
Even if our test remains empirically reliable under a non Poissonian framework, it could be therefore of interest to explore surrogate data method such as trial-shuffling. A very recent work based on permutation approach for delayed coincidence count with n = 2 neurons [5] is a first step in this direction but needs to be generalized to more than 2 neurons.
In this thesis, I applied the machine learning paradigm, succesful in many computing tasks, to historical linguistics. I proposed the task of word prediction: by training a machine learning model on pairs of words in two languages, it learns the sound correspondences between the two languages and should be able to predict unseen words. I used two neural network models, a recurrent neural network (RNN) encoder-decoder and a structured perceptron, to perform this task. I have shown that, by performing the task of word prediction, results for multiple tasks in historical linguistics can be obtained, such as phylogenetic tree reconstruction, identification of sound correspondences and cognate detection. On top of this, I showed that the task of word prediction can be extended to phylogenetic word prediction, which could be used for protoform reconstruction and a joint performance of word prediction and phylogenetic tree reconstruction in the future. By combining insights from two fields, machine learning and historical linguistics, this thesis provides some notable contributions. Firstly, to my knowledge, this is the first publication to use a deep neural network as a model of sound correspondences in historical linguistics. Secondly, in this thesis I propose a new cognacy prior loss, enabling a neural network to learn morefromsome training examples than from others. This new loss function has not yet given a clear performance increase in my experiments. I however hope it can be a first step in finding a method to learn more from cognate than non-cognate training examples, a key issue when applying machine learning to historical linguistics, and to other disciplines. Thirdly, I use embedding encoding, inspired by word embeddings in natural language processing, to encode phonemes in historical linguistics. In my experiments, his encoding seems to work better than existing one-hot and phonetic encodings. Furthermore, I developed a method to visualize learned patterns by a neural network by comparing clusterings of network activations and input and target words. Aditionally, in this thesis, I introduced a new method to infer cognate judgments from word prediction results. Finally, I propose phylogenetic word prediction, sharing weights between language pairs along a phylogenetic tree, which enables protofo reconstruction from a neural network. Results of the prediction models on different tasks are generally at the same level as baseline models. On the one hand, this means that I am not yet in a position to gather new insights about language ancestry from my models. On the other hand, the methods developed in this thesis do open up new possibilities. By extending the task to phylogenetic word prediction, the phylogenetic structure is immediately taken into account at prediction time. In the future, it may be possible to perform word prediction and phylogenetic tree reconstruction at the same time, by evaluating word prediction for different tree structures. Also, as shown with some first examples in this thesis, protoforms can be derived from the phylogenetic neural network. This is relevant, since protoform reconstruction is one of the tasks in historical linguistics for which fewer computational methods are already available.
A striking fact is that the simpler structured perceptron model performs better on word prediction than the more complex encoder-decoder model. Apparently, the larger number of parameters and potentially beneficial word-length independent representation between encoder and decoder, do not give a benefit. However, the encoder-decoder gives more possibilities to identify the learned reprsentations, by visualizing network layers. Also, the encoder-decoder has possibilities to be extended to a phylogenetic neural network, opening up new prospects, as described in the last paragraph. In the future, a fine-grained analysis of the solutions the network has found, possible using toy data expressing certain phonological changes, can be valuable. Another area on which future work could be performed, is phylogenetic word prediction. Experiments with different weight sharing strategies, with more language-specific encoders and decoders, could lead to better performance. Additionally, protoforms could possibly be improved by optimizing the network for the prediction of these forms, using a specific loss function.
With this thesis, I hope to contribute to future insights about the ancestry of languages. By applying computationalmethods in historical linguistics, advances havebeen made in recent years. In this thesis, I built further upon this development and proposed a central role for machine learning in historical linguistics. This is motivated both by a practical perspective, machine learning has shown successes in many other research areas, as well as by a fundamental perspective, the observed parallel between regular sound change and generalization in machine learning. I am looking forward to the new findings in historical linguistics that may follow from this new line of methods.
Artificial Intelligence has found a home in almost every discipline, from medicine to finance to construction. Although many people complain about their jobs being replaced by machines, the truth is that the machines are meant to serve us. With machine learning, the promise of truly intelligent machines is becoming closer to reality than it ever has been before. In finance, many of the top researchers in machine learning end up working for Wall Street companies, because of the applicability of their techniques in protecting investments and making informed decisions. Perhaps the thing that drives our economy truly is people figuring out new ways to solve problems. Neural Networks especially have become extraordinarily useful tools to solve problems. As we continue to strive to improve the world around us, we need powerful tools to make our efforts more effective. The real prediction is that in the future, we will see more problems being solved by artificial intelligence, and the world will be a better place for us all.
It is now very clear that the biological and computing world has a lot to gain from neural networks because of their ability to learn by example which makes them very flexible and powerful. In computation, they are very well suited for real time systems because of their fast response which are due to their parallel architecture. In areas of research such as neurology, they are used to model parts of living organisms and to investigate the internal mechanisms of the brain. Even though neural networks have a huge potential, scientist will only get the best of them when they are combined with computing.
In general, putting a neural network into a computer allows it to make intelligent judgments. Computerized neural networks can function in ways that are a huge improvement upon the brain's own processing mechanisms. Although, for some, it is easy to visualize how the huge number of neurons in the brain could provide the computational power that a person might need, it is difficult to explain why the brain is not better at forming complex mathematical judgments.
In all, neural network is a rich area of research which has the potential to capture perhaps a greater range of the operation of the brain than with only computational models. It should be noted that neural network do not perform magic, but can produce very exciting results if used intelligently, as this paper has attempted to explain some of its benefits, and the kind of task that a neural network excels at in computation.
The main aim of this thesis was to compare different painting classification methods. We downloaded data from WikiArt.org website using a web crawler which downloaded images of about 120x120 pixels size. We divided the classification task into two tasks. Task 1 which consists of two classes of color field painting and expressionism with 3000 samples. Task 3 which consists of five classes of color field, expressionism, impressionism, surrealism and realism with 6000 samples. The performance metric used was F1 score.
In this paper, we have introduced PrNNs ¨C a simple and yet powerful type of RNNs where all neurons are linearly activated. The learning procedure employs only standard matrix operations and is thus quite fast. No backpropagation, gradient descent, or other iterative procedure is required. In contrast to ESNs, also no washout period is required in the beginning. Any function can be approximated directly from the first step and with an arbitrary starting vector. The major innovation of PrNNs is dimensionality reduction. It means that not only network weights but also the network architecture is learned, leading to significantly smaller and sparsely connected networks. Although any time-dependent function can be approximated with arbitrary precision, not any function can be implemented by RNNs, in particular functions increasing faster than single-exponential. Nevertheless, experiments with reasonably large example and network sizes can be performed successfully within seconds on standard hardware, e.g., with the robot soccer dataset (cf. Sect. 5.3). However, if thousands of reservoir neurons are employed, the procedure may become numerically instable, at least our Octave implementation.
Using Izhikevich neurons, we have constructed a deterministic model which simulates the mode-locking of a single neuron to external sinusoidal forcing. However, real neurons have noisy responses. Traditional approaches cannot be directly applied here, so we developed a novel approach using a modified vector strength method in order to account for the stochastic nature of the system. Employing this method, we constructed Arnold tongue diagrams for a stochastic system in which we examined how the presence of noise influenced the degree to which mode-locking was observed.
This is of importance because neural encoding in the auditory system is inherently noisy. Inner hair cell (IHS) receptor potentials follow oscillatory motion, but are low-pass filtered. There is stochastic neurotransmitter release between IHS and auditory nerve fibers (AN) and the resulting action potentials reflect the time-varying nature of IHC membrane oscillations. AN fibers project to cochlear nucleus (CN) of the brainstem. The stellate cells in CN include choppers and onsets which differ in timing of the firing in response to periodic stimuli. This sensory coding includes mode-locking phenomenon and is also observable in higher levels of the auditory system such as inferior colliculus (IC) [3]. In order to understand and address these complex interactions, Arnold tongue diagrams of the cells aforementioned give us a global map in parameters space that could be used in justifying the observations.
Computational techniques used to investigate mode-locking have become an important tool in the analysis of synchronization. Recent investigations into periodic forcing have provided a wealth of information regarding the processing of temporal information and the characteristics of synchronization[19, 26]. Arnold tongues and other bifurcation structures in phase space can help us explain the neuronal behaviors seen in auditory signal processing neurons such as those in the cochlear nucleus[25] and inferior colliculus. The conclusions and methods presented here will be applied in the study of physiological data[25]. Utilizing raster plots containing spike times of neurons in response to a stimulus, we will fit the parameters of this model to period histograms produced from this data. Applying this methodology, we will construct the Arnold tongues of the particular neuron under study.
We derived a canonical model out of Wilson-Cowan model for single and two coupled oscillators that represents all kinds of bifurcations depending on the nonlinear terms present in the Taylor expansion of the model. These Wilson-Cowan oscillators can be excitatory and inhibitory populations that are interconnected in different regions of the brain. Depending on the oscillatory regime and coupling strengths, these examples exhibit different types of bifurcations. This means the future of the system can be explained and predicted by knowing the type of phase transition that will happen in the system. For example we have the development of periodic orbits (self-oscillations) from a stable fixed point (equilibrium), as a parameter (order parameter) crosses a critical value[28]. This type of phase transition refers to Hopf bifurcation. Calculating the Hopf bifurcation in the original Wilson-Cowan model is a difficult task. By obtaining the general normal form we found the bifurcation parameter of the system much easier for the case of Hopf bifurcation. We derived this special case in two different sections of the paper, one for a single oscillator and the other for coupled ones because of its importance in neuroscience . Stable oscillations in nonlinear waves may be another fruitful area and application[28]. We also obtained the time series diagrams for relative phase and amplitude of the two coupled oscillators. In this way we confirmed that the Hopf canonical model that we derived in the paper indeed exhibits Hopf bifurcation in the Wilson-Cowan model in a much easier way. By having the time series of the relative amplitude and phase of oscillators we can also obtain the period of oscillations and configure the equilibrium states of the systems. As a further step and application, if we know the anatomical properties of the nervous system in the brain which is unhealthy, by generalizing our model for population of neurons, we can treat the disease by changing the frequency of oscillations and consequently our order parameter ¦Á desirably. Good examples of these types of diseases are Tinnitus and Parkinson which are caused by unwanted oscillations of the nervous system.
In particular, we investigated whether selfish, reward-maximizing agents can be motivated to cooperate in the IPD game. This was done by finding an appropriate internal reward function which transforms the external payoffs into reinforcement signals that guide the agents to achieve the desired outcome, while these signals still satisfying the rules of the game. The search for such an internal reward function was performe dusingan revolutionary algorithm. This was motivated by how biological evolution hard-wires primary rewards in animals. The internal reward function is fixed for the lifetime of the agents, i.e., it does not change dynamically during learning. The results clearly showed that it is indeed possible to create such motivated agents using this approach, since Q-learning agents that used the reward transformation (RTQ agents) behaved significantly better than the ones that did not, without any change in the algorithm apart from the reward function. 
Our approach was inspired by work on intrinsically motivated RL that proposes the use of richer reward signals that are not necessarily directly related to solving the task intended by the designer. In our setting, the external payoffs are the extrinsic rewards given by the designer. In contrast, intrinsic rewards, while inherently enjoyable and can foster behaviors such as curiosity, play or exploration in animals (Schmidhuber, 2010), in our setting, they can be seen as altering the level of attained reward. In other words, in our approach, the reward received by the agents can be seen as being calculated by a function that takes as inputs both the extrinsic and some intrinsic rewards. Although in this work.
In the first part of our experiments, we performed an exhaustive analysis by investigating the effect of: (i) the lower and upper bounds of the search space of the internal reward values, (ii) the reward sign, (iii) the population size, and (iv) the mutation operators used. The evolved solutions suggestthatmutualcooperationbetweentheRLagentsisenhancedwhen: (i)T andR arepositive, whereas P and S are negative, (ii) T and R are close together, while P and S are close together as well, and (iii) the magnitude of the negative rewards P and S is high, whereas the magnitude of the positive rewards T and R is low. These results show that evolution finds a way to create agents that are motivated to cooperate, since it effectively creates rewards (i.e., positive reinforcement signals) and penalties (i.e., negative reinforcement signals) that ¡°point at¡± the goal.
The evolved payoffs could suggest that when an agent is ¡°losing¡±, the penalty should be much higher than the reward it accumulates when it is ¡°winning¡±. Interestingly, this concept can be paralleled with the WoLF (Win or Learn Fast) heuristic adopted by some MARL algorithms, where a smaller learning rate is used when the agent is winning and a much higher one is used when the agent is losing. Certainly, one cannot compare these two approaches, since algorithms that use the WoLF principle work online and very differently than the method we presented. Our goal was not to design another MARL algorithm, but to investigate the impact of evolving the payoff values in the IPD. It is interesting to note that in almost half of the evolutionary trials (14/30), the evolved reward function created agents that both converge to the ¡°Win-Stay, Lose-Shift¡± strategy. We believe that this strategy emerged so often due to the fact that the evolved rewards for winning are small, thus making an agent cautious when winning, while the evolved penalties for losing are large, thus making an agent altering its choice.
The experiments were then extended to the MARL case, i.e., when both agents use a learning algorithm. According to these results, the only agent that was able to rapidly converge to the CC outcome was the RTQ agent. All other agents did not converge with the given exploration schedule; however, it has to be noted that some configurations did manage to frequently choose to cooperate during the final rounds. In addition, the RTQ agents converged faster when both agents used high learning rates and low discount factors. This fast convergence of the RTQ agents might be due to the combination of high learning rates and low discount factors with the empirically chosen exploration schedule. In particular, this exploration schedule was chosen so as to achieve convergence to CC in less than 1000 rounds with the RTQ agents. Other homogeneous configurations (i.e., with Q and SARSA agents in self-play) benefit from high learning rates and low discount factors as well, since mutual cooperation is increased with these settings. Overall, the work presented in this chapter showed that it is beneficial to evolve the reward function of RL agents playing the IPD. Potential applications for MARL in the IPD arise in negotiations and conflict resolution with notable examples being the Cyprus problem and the Greek-Turkish arms race (Smith et al., 2000). Another interesting application is the modeling of how and when internal conflict can be resolved through self-control behavior. Real-world applications of MARL arise in many areas such as electronic marketplaces, video games, multirobot environments, distributed vehicle monitoring, air traffic control, network management and routing, electricity distribution management, distributed medical care, evacuation operations, military applications and many others. Future work in this area, related to this study, should focus on methods that find reward functions for agents which operate in more complex and partially observable environments with high dimensional state-action spaces and inhabited by a variety of learners (not just in self-play). In such problems, it might be difficult even for evolutionary methods to design a good reward function. For this reason, evolutionary methods could be used alongside intrinsic motivation systems, reward shaping, as well as inverse RL techniques. The latter are methods that recover reward functions from expert demonstrations and subsequently learn near-optimal policies for these reward functions. Such an endeavor opens up a broad avenue of future directions, which could ultimately lead to truly adaptive and autonomous multiagent systems. In this chapter our focus was on making the agents converge to a stationary policy in a multiagent learning setting with 4 states and 2 actions. This setting was selected because it is one of the simplest possible, but still challenging dynamic environments. In the next chapter, we move on to a more complex multiagent learning scenario where the agents cannot converge to a stationary policy and they are required to continuously adapt to the changing behavior of the other agent.
In this work, we explored a combination of the MAXQ hierarchical value function decomposition method with the algorithms PHC and WoLF-PHC that were created for multiagent learning settings. The newly created algorithms were evaluated first in two single-agent taxi domains and compared with the algorithms Q-learning, SARSA, MAXQ-Q, PHC and WoLF-PHC. For Q-learning and SARSA, we used both greedy and Boltzmann exploration. We then evaluated all algorithms in a partially observable multiagent taxi task which illustrated the strength of our approach: the MAXQ decomposition worsens the performance of naive, single-agent learning algorithms, such as Q-learning, whereas it improves the performance of the PHC and WoLF-PHC multiagent learning algorithms, in such settings. In other words, our newly proposed MAXQ-PHC and MAXQ-WoLF-PHC algorithms create more adaptive agents than all the other algorithms we tested. Certainly, a direct comparison with other studies that use multiagent taxi domains cannot be made, as their tasks were different than ours In the single-agent settings, Q-learning was found to be more efficient with ?-greedy exploration compared to SARSA, which was more efficient with Boltzmann exploration. PHC and WoLF-PHC had good results even though they are algorithms for multiagent learning settings. MAXQ-Q was more efficient with ?-greedy exploration than with Boltzmann exploration. All algorithms that used the MAXQ method had better results in the ETP compared to their performance in the TP in relation to all other algorithms; this is due to the increased state-action space of the ETP which helped in delineating the strength of the MAXQ hierarchy. One would wonder then how the MAXQ-PHC and MAXQ-WoLF-PHC algorithms fare in a multiagent version of the ETP. At this point, it has to be noted that the curse of dimensionality is still a major problem for the work presented in this chapter, since we have not used any form of state abstraction. To illustrate the explosion of the state space using the multiagent task in the ETP, a rough calculation indicated that each table (Q-table, policy, or average policy) for each agent requires approximately 2.5GB of memory. The problem is not only a matter of storage, but a matter of generalization and speed of learning. For these reasons, it would be very beneficial if state aggregation (Singh et al., 1995) or abstraction is employed (even though it was not the focus of this study) in order to reduce the number of parameters needed to achieve generalization in such
large state-action spaces. MAXQ facilitates the use state abstraction (Dietterich, 2000), therefore, using state abstraction would increase the performance of all MAXQ algorithms. Note that state abstraction can be related to relaxation methods used in mathematical optimization and some work exists in using relaxation methods for dynamic programming. An interesting investigation would be on general relaxation methods to reduce the size of the state space in RL problems where the model of the MDP is not known, in contrast to dynamic programming. As this is related to function approximation and feature extraction, it is interesting to note that a framework known as feature MDP has been proposed in the literature to reduce complex unstructured MDPs to smaller ones using information theoretic principles. This work was extended to the case where there is structure in the MDP resulting in the feature dynamic Bayesian network framework.
The MAXQ method assumes that the hierarchical structure of the task is given by the designer. A fundamental problem in RL is how to automatically find this hierarchical structure online. Algorithms such as HEXQ (Hengst, 2002) and HI-MAT are examples of how this can be done. An interesting exploration along the lines of the work presented in this chapter would be the investigation of how such hierarchical algorithms perform in multiagent settings and whether they could be hybridized with multiagent learning algorithms such as PHC, WoLF-PHC or others. Automatically learning the state abstraction is also an exciting research avenue; this could be based on semi-MDP homomorphisms. An interesting combination of MAXQ with model-based learning is the algorithm R-MAXQ which has also been extended using function approximation to yield an algorithm called ¡°fitted R-MAXQ¡±. This algorithm effectively fuses the ¡°practically optimal R-MAX algorithm of Brafman and Tennenholtz (2003) that learns a model of the environment, with the MAXQ method and ¡°averagers¡±, an important form of function approximation that is ¡°well-behaved¡± when coupled with RL methods. This makes it possible to perform efficient exploration and learn the model of an MDP that has continuous state variables given the hierarchical task structure. A model-free approach to efficient exploration and hierarchical learning could also be investigated by combining the MAXQ method with delayed Q-learning (Strehl et al., 2006); additionally utilizing function approximation, as in fitted R-MAXQ, could offer advantages in continuous domains. In addition, utilizing mechanisms for disambiguating the state could help in partially observable environments. Interestingly, certain such non-Markovian tasks can be automatically decomposed into Markovian subtasks and be solved efficiently.
A heterogeneous setting where the agents in the environment use different learning mechanisms could be further explored. This will demonstrate how the behavior of the agents changes and whether the agents can coordinate their actions. If the agents cannot coordinate their actions then communication protocols between the agents could be established by sharing certain information. An example of an algorithm that gives the opportunity for agents to communicate is the WoLF-Partial Sharing Policy (Hwang et al., 2007) which is an extension of WoLF-PHC. This algorithm could undergo hierarchical extension using the MAXQ decomposition. Moreover, as SARSA did not perform very well in the multiagent scenario, on-policy versions of the PHC and WoLF-PHC algorithms could be investigated, that combine the sampling mechanism of the SARSA algorithm, and the policy update mechanisms of the PHC and WoLF-PHC algorithms respectively. Furthermore, all these could be extended hierarchically using the MAXQ decomposition and compared. Finally, directed exploration methods (Thrun, 1992) could be utilized and compared with the undirected exploration methods we used in this study.
In conclusion, our experiments have demonstrated that as the state-action space grows, the MAXQ decomposition becomes more useful as it speeds up learning in both single-agent RL and MARL problems. In partially observable MARL problems, using a naive learning algorithm with the MAXQ decomposition can be ineffective, whereas the introduction of the PHC and WoLF- PHC mechanisms creates more adaptive agents.
In this work, we investigated an approach for representing local learning rules using ANNs.
We demonstrated that such a representation can be effective, by finding (through evolutionary optimization) ANN-based rules that perform well in partially observable versions of four environments: the mountain car, the acrobot, the cart pole and the NS mountain car. The evolved rules were compared with the SARSA(¦Ë) learning algorithm which uses a linear function approximator and tile coding for feature extraction. While the results showed that the evolved rules perform better than the version of SARSA that is provided with partial state information, such a comparison is not fair because SARSA is a general algorithm, whereas the evolved rules are very specific to the tasks. Moreover, the evolved rules have 100 generations head start on the SARSA variants, however, the effect of this overhead would diminish as we increase the number of subsequent tasks being performed, since our goal is to eventually create more general rules. The purpose of the comparison was to show that the ANN representation of the learning rules can be effective in (i) partially observable settings, as its performance was comparable to the performance of a well established learning algorithm which, however, was provided with full state information, and (ii) nonstationary environments, where fast adaptation is needed. Our approach solved each individual problem near-optimally, even though the evolutionary algorithm only optimized the six parameters of the learning rule and not any parameter of the controller in each scenario. A noticeable trend in all simulations is that the evolved rules converge very fast and suggest that most optimization occurs offline (i.e., during evolution) rather than online. This is due to the methodology adopted in this study, where the purpose was to overfit the rules to the tasks in order to examine whether such ANN representations are effective. For this reason, if the currently evolved rules are transferred to different domains, they will most probably not perform well. Alternative methodologies, where generalized environments (Whiteson et al., 2011) or multiple domains are used during the fitness evaluation, could possibly show that such ANN-based rules can be used in more general settings. In such methodologies, the number of episodes of the RL simulations (during the fitness calculation) should be large, in order to allow for more online optimization.
Apart from experimentation with more environments (as mentioned above), it is important to explore nonstationary environments in more depth. This could potentially be done using the nonstationary mountain car and omitting certain nonstationary cases. Some preliminary experiments showed that by including all cases (i.e., changes in difficulty level) in the schedule, the rules became more robust. A follow-up study could be done where the schedule during the fitness evaluations is varied systematically (between experiments). This would enable conclusions to be drawn regarding the robustness of the emerged rules as a function of the provided schedule. Related to what is discussed above, there is an issue with time scales in nonstationary environments. In particular, we can identify the following time scales: (i) evolutionary, (ii) environmental change (nonstationarity), (iii) agent-environment interaction (stimulus-response), (iv) controller activation, and (v) learning rule operation. The evolutionary time scale is the slowest one within the time frame of which training/optimization of the rules is performed (offline). The time scale of controller activation in our experiments was set to be the same with the time scale of agent-controller interaction, i.e., the controller is activated for just one time step for every observation. The learning rules of our approach can be seen as operating in a somewhat faster time scale than the agent-environment interaction, due to the recurrent connection on the output neuron; that is, even though the learning rule networks update the respective controllers at every time step of the agent-environment interaction, they are required to be activated multiple times. The only remaining time scale is the time scale of the environmental nonstationarity. If the world changes very quickly, the agent cannot adapt. For this reason, we designed our experiments so that the world changes after some episodes and not after certain time steps, however, providing a maximum number of steps per episode. We could then ask the following: (i) How can an agent ¡°feel¡± that the world is changing? The answer to this question lies in the recurrent connections of the output layer of the controller network. That is, the process of ¡°feeling¡± that the world is changing is not explicit, but is done implicitly through the memory created by the recurrent connections. (ii) Does the agent learn to learn faster as necessary given these different time scales? This demands further investigation as it is not clear whether this happens, for example, in the nonstationary task we investigated. For example, one could disable the learning rule after it makes a controller settle to a solution for a given difficulty level, and when the difficulty level changes, the performance of the controller should be compared to the performance of the controller-learning rule combination.
This needs to be studied carefully though since it is not known what the effect of disabling the learning rule would be. This is because evolution might have found a solution where changes from the learning rule keep the controller stable and disabling the learning rule could make the controller diverge. An interesting future work would be to design specific experiments so as to provide concrete answers to both of these questions.
Evolutionary algorithms are examples of gradient-free optimization methods. As mentioned in the introduction, gradient-based methods could potentially be used if a cost function could be formulated. This could be the subject of a separate study, as it demands a further and a more extensive investigation. The cost function could potentially be related to the accumulated reward, and techniques used in policy gradient methods could provide some direction with regards to the training procedure. Finally, it is worth mentioning that gradient information could be used in a different way in our system: as an extra input to the learning rule network. Therefore, if gradient information is available this could be used to either train the learning rule or as part of the function of the learning rule. Utilizing gradient information could offer benefits such as accelerated optimization of the learning rules. It could, however, have disadvantages due to local optima, therefore, an exciting prospect for future work would be to explore this direction. Moving towards the goal of evolving more general learning rules, we identify some issues that need to be taken into consideration. The first has to do with stability, which could be viewed as equivalent to generalization. Intuitively, stability notions measure the sensitivity of the learning rules to perturbations in the training dataset. The training set in this case contains environments and their parameters. An open research direction therefore for the future could be the investigation of methodologies or experiments in which evolved rules are stable in multiple environments. A second issue is convergence. In TD learning, convergence can be seen in the form of a decreasing TD error, especially in stationary environments, where the error can approach zero. In this work, convergence was not addressed explicitly, even though the fitness function for stationary environments took into account the performance in the last episodes of the simulations. One way to explicitly account for convergence could be to check whether the magnitude of the weight changes produced by the learning rule gets minimized. An approach would be to view convergence as another objective and use a multiobjective optimization algorithm to create rules that are both high performing and convergent. A further issue is optimality. In more general environments, the rules need to be able to address the exploration/exploitation problem online. In this work, this problem was addressed mostly offline, by evolutionary adaptation, and as a result, the rules became very specific to the tasks. How experiments can be designed in which local RL rules emerge that behave optimally in a no-regret, a Bayesian or a Probably Approximately Correct (PAC) sense, remains an open question. The focus of future work in this area should be to explore such interesting research avenues.
When designing intelligent agents, it is often desirable to endow them with the ability of switching between different behaviors in response to environmental changes. This chapter presented a computational model of an artificial neuron, called switch neuron, that was shown to capture such a property. The model works by allowing only one of its incoming connections to propagate forward. This connection is determined by the level of modulatory activation of the neuron which is affected by modulatory signals. While these signals could encode some information about the reward, they are qualitatively different in the sense that both positive and negative signals are interpreted as instructions to change the selected connection, and the sign determines the direction of change. An important design aspect of the switch neuron is that it can send its own modulatory signals, thus, modulate other switch neurons. This is done by using the switch neuron as part of a three-neuron module with the others being: (i) a neuron (called the modulating neuron) that collects the incoming modulatory signals and modulates the switch neuron, and (ii) a neuron (called the integrating neuron) that integrates the modulatory signal emitted to the switch neuron, fires above a threshold and is used to communicate with other switch modules or individual switch neurons. We showed that a topology where these switch modules are placed sequentially on the same modulatory pathway explores in a principled manner all permutations of the connections arriving on the switch neurons.
The model was tested in two sets of nonstationary tasks, where the reward function changes over time, namely nonstationary association tasks and T-maze domains. We presented appropriate switch neuron architectures that can learn one-to-one, one-to-many, many-to-one and many-to- many binary association tasks, and discussed how to extend them for an arbitrary number of inputs and outputs. Architectures were presented for the homing and non-homing T-maze tasks as well, where we discussed how to extend them for an arbitrary number of sequential decision points. For all tasks, the switch neuron architectures were clearly shown to generate optimal adaptive behaviors, thus, providing evidence that the switch neuron model could be a valuable tool in simulations where behavioral plasticity is required.
The current PhD thesis explores the areas of reinforcement learning (RL) and adaptive neural networks. While the works presented in each chapter are all independent from one another, they do have the common theme of accelerating adaptation in dynamic environments. It is well known that in MARL the presence of multiple learning agents creates a dynamic environment from the viewpoint of each agent. The presence of a structure in the task offers the opportunity for the agents to accelerate their learning through decomposition of the task into subtasks which can be reused. The modeled scenario is the single-agent taxi problem which we extended to the multi-agent case to make it more challenging. We have also made it partially observable to introduce uncertainty and the requirement of continuous adaptation. In Chapter 4 we ask whether we can create adaptive agents by evolving their learning rules in three stationary tasks and more specifically the mountain car, the acrobot, the cart pole, and a nonstationary one and in particular the nonstationary mountain car. All tasks are partially observable in order to make the problem faced by the learning rules more challenging. Finally, Chapter 5 investigates nonstationary, binary association tasks where the agent needs to learn how to associate arbitrary input-output patterns. The associations change at regular intervals, therefore, the agent needs to forget the previous associations and learn the new ones. Additionally, Chapter 5 investigates partially observable T-maze domains where the agent needs to find the end of the maze that provides high reward, remember it and continue to go there until this high reward is moved to a different maze end, at which point the agent needs to explore in order to find the maze end again.
We investigated an approach where both the policy and the learning rule are represented as neural networks. We used evolutionary algorithms to optimize the learning rules. In order to compress the space of learning rules, we investigated local rules (akin to Hebbian synaptic plasticity rules) with a fixed architecture (but evolvable parameters) that modify only the weights of the policy network and not its structure. The results showed that even the simple, constrained architecture of the learning rule network was capable of encoding a rule that adapted the policy network towards a near-optimal policy from as early as the 2nd episode in the stationary tasks; the performance of the evolved rules in these tasks was comparable with the performance of SARSA(¦Ë) with tile coding that is provided, however, with full state information. In the nonstationary task, the learning rule and policy networks created an agent that displayed adaptation to the dynamics of the problem. Although not optimal, its performance was significantly better than the performance of SARSA(¦Ë) with tile coding that uses full state information (but does not know when the dynamics of the problem change). When SARSA(¦Ë) was provided with partial state information in all tasks (but used the previous observation and action as an additional part of the state), its performance was always worse than the performance of the evolved rules. The conclusion is that adaptive agents can indeed be created using this approach. A broader implication emerges when known learning rules from the literature are constructed as computational graphs similar to neural networks. This can be done by utilizing activation functions other than the usual logistic and hyperbolic tangent functions. For example, a multiplicative unit is needed to be the output unit of the learning rule network, in order to express the function of the standard Hebbian rule. If the architecture of the learning rule networks is allowed to change, then the structure/equation of the learning rule becomes more flexible. By utilizing state-of-the-art neuroevolution algorithms, it should be possible to construct more general learning rules that fuse properties of different known learning rules. This means that a single unifying equation (i.e., network architecture) could capture the equations of many learning rules just by changing some parameters (i.e., weights). An exciting prospect arises if this equation has less free parameters than the sum of parameters of the learning rules it unifies.
We introduced a new type of neuron we call switch neuron, that is able to gate all but one of its incoming synaptic connections. Modulatory signals arriving on the neuron can control which of these connections are gated. We additionally introduced a way of making these neurons modulate other switch neurons. This is accomplished by appropriately constructing a module of three neurons, one of which is the switch neuron. We showed that these modules can be placed on a modulatory pathway and achieve the desired effect of optimally exploring all permutations of the incoming connections of their switch neurons. Furthermore, we designed appropriate neural network architectures, that use switch neurons, for all problems tested: (i) one-to-one, one-to-many, many-to-one and many-to-many binary associations, and (ii) T-mazes where the agent needs to navigate to a maze-end (non-homing scenario) and return home (homing scenario). We showed that these architectures achieve adaptation in an optimal number of steps every time the problem changes. The conclusion, therefore, is that this type of neuron and the three-neuron module could be valuable tools in experiments and applications where adaptive neural networks are needed.
Reflecting upon the general problem statement and the purpose of this thesis, we could say that our work contributed to accelerating adaptation in dynamic environments. This was done by starting from the simplest multiagent settings, moving on to more complex ones where the task is structured, and then switching to single-agent settings where we explicitly control the change in the state transition function, T, and the reward function, R. In all types of dynamic environments we prescribed certain mechanisms that have clear advantages over known methods. It has to be noted that the techniques presented in all contributing chapters are concerned with the problem of learning in changing environments, apart from Chapter 5 where the mechanism of switch neurons is not only capable of quickly learning, but also of forgetting associations. This ¡°forgetting¡± process seems to be crucial in noisy and uncertain environments that are dynamically changing, since old memories need to be overwritten with new ones. This is backed up by evidence illustrating the beneficial role of forgetting in memory and learning. Forgetting has also been incorporated as an extension to the long short-term memory (LSTM) artificial cell through the form of ¡°forget¡± gates, making the cell able to learn when and what to forget; this effectively increases the performance of LSTM recurrent neural networks in tasks that require memory illustrating that ¡°forgetting¡± facilitates learning. Finally, let us discuss to what degree the presented methods could be treated in a deeper mathematical way. We think one could possibly prove something related to the algorithms converging to a best-response policy, to Nash equilibria or to Pareto-optimal ones based on certain characteristics of the evolved payoff matrix; folk theorems (Leyton-Brown and Shoham, 2008) could possibly be utilized. We think that one could possibly investigate whether MAXQ-PHC and MAXQ-WoLF-PHC converge to recursively optimal policies (as MAXQ-Q does) or whether they converge to some mixed-strategy Nash equilibrium (as PHC and WoLF-PHC try to achieve). 
In this thesis we have focused on the topic of temporal information processing in the brain that also leads to memory guided behaviors, using a closed-loop system approach. In this regard, we showed that using an input-driven recurrent neural network model (as abstraction of abundant recurrent neural circuitry in the brain) with novel, local, self-adaptive or plastic processes, enables it to robustly perform such temporal processing. In the first part of the thesis, we introduced the concept of input driven recurrent networks (RNN) from the point of view of
non-autonomous dynamical systems. We demonstrated that a generic class of such RNN models can be used to approximate to arbitrary levels of accuracy, any finite time trajectory of time varying dynamical system. Considering the brain receives a constant barrage of complex time-
varying stimuli and needs to compute with them, our model based on input-driven RNN forms an ideal setup to investigate the underlying processes for such temporal processing. Furthermore, our network model (also referred to as self-adaptive reservoir) forms a special case of this generic
class of RNN models. In this chapter, we introduced two novel forms of local adaptations at the level of single neurons of the recurrent network. Firstly, an adaptation technique for the modulation of neuronal timeconstants or decay rates was presented, based on a new information theoretic measure called local active information storage. This allows each individual neurons to adapt their timescale with respect to the timescales of input signals and their own history of activity (local memory). Secondly, we derived a generalized intrinsic plasticity mechanism based on an optimal Weibull output distribution, in order, to tune the parameters that control the shape and scale of individual neuron non-linearity inside the network. As a result, the network was able to maintain homeostasis of neuronal activity, while at the same time allowing maximum information flow between input and output of each neuron. Finally, we combined this with a supervised plasticity mechanism to adapt both the connection strengths inside the recurrent network as well as the connections from the recurrent network to readout neurons, which were trained for specific temporal tasks. Overall, this presents a novel self-adaptive reservoir model (SARN) for which we demonstrated, significantly superior performance as compared to static RNN models using an initial signal modeling task with inherently slow and fast timescales. We presented further elaborate experimental results demonstrating the superior performance of SARN in three different time-series benchmark tests, involving both non-linear computational power and temporal memory capacity. Furthermore, using delay embedded patterns generated by the Mackey-Glass time series, it was shown that, unlike non-adaptive static networks, SARN could learn to generate both stable as well as chaotic patterns. This occurs naturally from its intrinsic dynamics, in an input dependent manner. Post-adaptation, the over all network dynamics resides in a near critical region (edge of chaos), which leads to optimal processing of temporal information in the network. Using a clock-like, time interval processing task, we show that our network reproduces a linear increase in temporal variability with increase in square of the interval duration. This correlation that has been widely observed in experimental data, is well captured by our model, and as such, it shows that local plasticity or adaptation mechanisms may indeed be responsible for time perception in the brain (atleast, in the fast timescale of milliseconds to minutes). Of course, time perception in the brain, does not occur in isolation, but is intricately related to forms of behavior and memory. Therefore, using a closed-loop system with a complex walking robot, we demonstrated the application and superior performance of SARN on a delayed T-maze navigation task. Specifically, this required the maintenance of temporal stimuli (cue signals) and then later recall these at the T-junction, after varying delay periods, in order to make corresponding decisions. As such, this displayed SARN¡¯s ability to, not only generate precisely timed outputs, but also achieve extended memory of time-varying stimuli, that guides future behaviors. Finally, we also demonstrated that our local adaptation mechanisms complement the inherent transient dynamics of the network, by successfully learning a complex time dependent motor behavior like handwriting generation. Briefly active input stimuli were successful in enabling stable dynamic attractors (trajectories) in the high dimensional network state space, such that, motor patterns can be generated even in the presence of relatively high levels of perturbations. These results were compared with two state of the art RNN models, namely static chaotic RNN and a more recent ¡¯innate trained¡¯ plastic RNN model, demonstrating SARN¡¯s superior performance in both cases. In essence, our results clearly indicate that homeostatic mechanisms like intrinsic plasticity and local neuronal timescale adaptations, can indeed enable robust learning of temporal patterns and memory guided behaviors, in a biologically plausible manner. 
Motor prediction and planning is largely dependent on robust temporal information processing in the brain, especially in the milliseconds to seconds timescale. Furthermore due to the inherent delays in sensory information, internal forward models (Wolpert et al., 1998) are believed to be a mechanism by which the brain overcomes these delays and makes predictions of future motor signals. The modeling of such a predictive mechanism needs an intrinsic memory of recent motor commands, and an ability to adapt with changing sensory feedback signals. As such, in Chapter 4, we presented a novel neural mechanism to combine motor patterns generated by the central nervous system of a bio-inspired walking robot with internal forward models, based on our self-adaptive reservoir network. By designing SARN based forward models that works for each leg of a hexapod robot, in a distributed architecture, we clearly demonstrate the ability of our adaptive network to perform robust motor predictions. This enabled the walking robot to generate complex locomotive behaviors like climbing over large obstacles, crossing gaps and navigate uneven terrains. Furthermore, comparison with previous simple recurrent neuron forward models (Manoonpong et al., 2013b) demonstrate that SARN enables the robot to learn such predictive behaviors, in a much faster and stable manner. These results, highlight the robust
performance of SARN, as well as, show a crucial link between the effect of plasticity in recurrent networks and the resulting adaptive behaviors. Moreover, unlike previous plastic RNN models, which have been mainly applied to synthetic time-series modeling tasks; here, we demonstrate that the performance gained by SARN over static RNN models in synthetic tasks, can be easily transferred to complex engineering problems. Finally, in chapter 5 we extend the previously presented supervised learning setup of SARN, to a more generic reward-based learning mechanism. This is crucial, since for biological systems, evaluative feedbacks from the environment in the form of rewards or punishments form an important component for developing conditioned responses. In this regard, here we specifically present a temporal-difference learning mechanism (W?rg?tter and Porr, 2005) for adapting the synaptic connections from the recurrent layer in SARN to the readout neurons, in order to, learn some goal-directed behaviors. This is motivated as an abstract model of the basal-ganglia neural circuitry. Furthermore, in line with recent experimental evidences for the cooperative role of the striatal and cerebellar systems (Bostan et al., 2010), we show that, the reservoir reward learning system in combination with a correlation learning based model of the cerebellum, can lead to more efficient and stabler goal-directed decisions. We also introduced a novel biologically plausible, reward modulated heterosynaptic plasicity rule that can perform such a combined learning. Furthermore, it is clearly demonstrated that SARN outperforms traditional feed-forward neural network models for reward learning, specially in scenarios with inherent dependence on memory of incoming time-varying stimuli. Overall, the results obtained in this chapter clearly motivate the neurobiological grounding of our adaptive model from a realistic reward learning perspective, that can work in conjunction with other unsupervised learning strategies in the brain. 
Understanding temporal information processing and dynamics of memory underlying large recurrent neural networks is essential, since this could explain the relationship between such dynamics or processes, and the resultant timing mechanisms in the brain. As such, several recent works have used artificial recurrent neural networks to model cortical functions like memory and learning that could underlie the brains ability to tell time. The model presented in this thesis, also follows a similar approach, arguing that temporal processing or timing is inherently generated by the dynamics of large recurrently connected neurons. However, although some previous models have been able to capture the results obtained from time perception based psychophysical studies, they have hitherto, not been applied for complex temporal processing tasks, especially in realistic closed-loop scenarios. In this thesis, we bridge this apparent gap of knowledge by introducing local adaptation and homeostatic plasticity in the recurrent network. As a result, we demonstrate for the first time, that post adaptation, initially random recurrent networks can be trained to generate complex temporal patterns and long memory of incoming stimuli. Different inputs can result in distinct locally stable or chaotic trajectories through the network space that is responsible for such robust temporal processing. These can then be used to generate complex memory guided behaviors in artificial agents. Previous work on similar self-organized adaptation of RNNs with a combination of homeostatic plasticity and synaptic plasticity, have either used simplistic binary neuron models with applications only on simple time-series data, or optimized the network based on specific type of neuron non-linearity. Furthermore, all such models have been formulated within a supervised learning paradigm. As such, these models fail to explain the information processing ability in the brain that lead to complex sensorimotor processing. In comparison, the SARN model presented in this thesis, shows that intrinsic plasticity and neuronal time constant modulation can not only adapt the network in a self-organized manner, but also generate complex behaviors in a biologically plausible way. This works not only in presence of specific teacher signals required for supervised learning, but also in the presence of realistic reinforcements (rewards or punishments) from the environment, based on instrumental conditioning in the brain. Moreover, the combination of IP, and local active information storage, based neuron time constant adaptation can be seen as a direct intervention at the algorithmic level of neural computation. Such that, the level of information storage in the system can be adjusted in order to affect the higher-level computational goal of enhanced performance, on time processing tasks requiring large delay memory capacity.
However, it should be noted that an unrealistic aspect of our current model is the use of hyperbolic tangential neurons which can produce both positive and negative firing activity. Although this works best for computational purposes, from a biological perspective this violates Dale¡¯s
principle, according to which neurons can be either excitatory or inhibitory, but not of a mixed type. This could be ameliorated by the use of more realistic sigmoidal neurons (activity ¡Ê [0,1]) with separate excitatory and inhibitory types. As the intrinsic plasticity scheme presented in this thesis is based on a generic Weibull distribution, this could easily be adjusted by appropriately selecting the shape and scale parameters of the distribution, in order to account for the sigmoidal non-linearity shape. Although in our present model, local adaptations and plasticity mechanisms provide guided self organization, leading to significant improvement to the temporal information
processing capability of RNNs, a number of open questions remains that can be addressed with future work. Some of them being: The reservoir models presented in here, demonstrate that complex (transient) dynamics enables neural circuits to process a broad range of nonlinear, temporal problems. This is largely based on the inherent stochasticity (randomness) of neural systems and local adaptation processes that occur at a fast timescale of milliseconds to seconds (like the ones presented in this thesis). However, it is known that slow synaptic plasticity mechanisms (minutes to hours) in the brain adapt synaptic efficacies to form ordered structures - called cell assemblies. These form strongly interconnected clusters of neurons that can encode associative memories of previously experiences stimuli. Typically this type of dynamics is characterized by persistent or steady state activity, and is in stark contrast to the transient dynamics of randomly connected reservoir networks. Intriguingly, several experiments show that both concepts coexist in the same neural circuits. As such, this begs the question, how this coexistence of transient dynamics and cell assemblies can emerge in one neural circuit? and what role does local adaptations and homeostatic plasticity play in this process? Extension of the current model using a combination of Hebbian synaptic plasticity (instead of the supervised learning presented here) along with the homeostatic plasticity mechanisms, would be needed to address these questions.
Here we extended the SARN model to work from within a reward learning paradigm. Typically the synaptic connections from the reservoir or recurrent layer was learned using a neuromodulatory signal based on the temporal difference error. Such a neuromodulatory, reward prediction error signal are believed to be encoded primarily by dopaminergic neurons. Experimental evidence suggests that dopaminergic neuromodulatory signals, typically modulate synaptic plasticity in the brain, specifically in the prefrontal cortex (Otani et al., 2003). Therefore, it is plausible that such modulation of synaptic efficacies occurs within the recurrent layer of our model, so as to bring about task specific representations. In future work, the interaction of such modulatory processes with fast homeostatic and slow synaptic plasticity mechanisms within the dynamic reservoir could be investigated.
Finally, although here we specifically focused on the active information storage at single neurons, in order to adapt their decay rates or time constants; neural activity in networks is not only dependent on its own previous history but also the flow of information from neighboring neurons. The use of measures like transfer entropy or Granger causality help quantify such information. Therefore, it would be interesting to use both transfer and storage measures to adapt neuronal decay rates. Such a combination could provide a measure for the true modified information at a single neuron level as a result of changes in the timescale of inputs.
Overall, the work presented in this thesis provides the crucial link between homeostatic mechanisms and local unsupervised adaptation processes in neuronal networks and their effect on the networks ability to perform complex temporal information processing. This also forms a novel self-adaptive framework for modeling time perception and related behaviors in the brain. Furthermore, using a closed-loop approach, it clearly demonstrates how robust memory guided behaviors can be generated from the resultant transient dynamics of such an adaptive network.
This was hitherto not shown in static recurrent neural network models. As such, it lays the foundation for future work, that can answer some of the critical questions raised above.
Data mining in fencing provides serious advantages to its users. It makes it possible to apprehend all important elements of a fencing sport and to extract knowledge from the data collected. In this way, fencers get to know themselves, because they are able to see what they need in order to win, where they mostly make mistakes, which elements of the game call for improvements... Moreover, using fencing analysis and data mining as the highest level of analysis, teams may know their opponents and prepare tactics for the game. Fencing scouting, as well as the analysis of their own and the opponent¡¯s team, has become the essential part of preparation for all games in professional leagues. The general conclusion of all the analyses is that the sport under the hoop is crucial for winning the game. In defense, it is important to catch the opponent¡¯s sword
after the opponent's attack and preventing them from next offensive attempt, while in offense it is most important to be precise under the hoop or to score "points in the paint". The data collected are relevant for the Egyptian Fencing Federation, and the model created may be applied to other federations of similar quality. It is to be expected that some higher-quality federations or lower-quality ones, as well as junior leagues, would create somewhat different models.
The flaw in keeping statistics with most of the existing programs is that a large number of fencing elements remain undocumented. With those programs, we do not know which fencer guarded which opponent, how much fencers run in offense and defense, which moves they performed. In order to obtain more complete knowledge about the game and to discover some new patterns, we need a richer data set and new software solutions so that by subsequent appraisal of a game we document all relevant events.